#!/usr/bin/env python3
"""
Adaptive Learning Pipeline –∑–∞ OU2.5 Per-League Models

–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–∞–Ω –º–æ–¥—É–ª –∑–∞:
- Drift detection –≤ per-league –º–æ–¥–µ–ª–∏
- Incremental retraining –ø—Ä–∏ –≤–ª–æ—à–∞–≤–∞–Ω–µ –Ω–∞ performance
- Backup –∏ rollback –º–µ—Ö–∞–Ω–∏–∑–º–∏
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –∞–¥–∞–ø—Ç–∞—Ü–∏—è
"""

import sys
import os
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

import json
import pandas as pd
import numpy as np
import joblib
import shutil
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Any
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import yaml

from core.utils import setup_logging, load_config
from core.league_utils import LEAGUE_ID_TO_SLUG, get_league_display_name, get_per_league_model_path
from core.ml_utils import prepare_features, get_feature_columns, evaluate_classification
from sklearn.model_selection import train_test_split
from sklearn.isotonic import IsotonicRegression
import lightgbm as lgb


class AdaptiveTrainer:
    """
    Adaptive Learning —Å–∏—Å—Ç–µ–º–∞ –∑–∞ per-league OU2.5 –º–æ–¥–µ–ª–∏
    """
    
    def __init__(self, config_path: str = "config/adaptive_config.yaml"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ AdaptiveTrainer
        
        Args:
            config_path: –ü—ä—Ç –∫—ä–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–∏—è —Ñ–∞–π–ª
        """
        self.config = self._load_config(config_path)
        self.logger = self._setup_logging()
        
        # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self.models_dir = Path(self.config['models_dir'])
        self.backup_dir = Path(self.config['backup_dir'])
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –∏—Å—Ç–æ—Ä–∏—è
        self.metrics_history = {}
        self.current_metrics = {}
        
        self.logger.info("ü§ñ AdaptiveTrainer –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω")
    
    def _load_config(self, config_path: str) -> Dict:
        """–ó–∞—Ä–µ–∂–¥–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è—Ç–∞"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            return config['adaptive_learning']
        except Exception as e:
            # Fallback –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
            return {
                'enabled': True,
                'drift_threshold': 0.05,
                'retrain_min_matches': 300,
                'retrain_window_days': 90,
                'backup_old_models': True,
                'log_file': 'logs/model_reports/ou25_per_league_summary.json',
                'models_dir': 'models/leagues/',
                'backup_dir': 'models/backups/',
                'adaptive_log': 'logs/adaptive_learning.log'
            }
    
    def _setup_logging(self) -> logging.Logger:
        """–ù–∞—Å—Ç—Ä–æ–π–≤–∞ logging –∑–∞ adaptive learning"""
        logger = setup_logging()
        
        # –î–æ–±–∞–≤—è file handler –∑–∞ adaptive learning
        log_file = self.config.get('adaptive_log', 'logs/adaptive_learning.log')
        os.makedirs(os.path.dirname(log_file), exist_ok=True)
        
        file_handler = logging.FileHandler(log_file)
        file_handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
        
        return logger
    
    def load_current_metrics(self) -> Dict:
        """
        –ó–∞—Ä–µ–∂–¥–∞ —Ç–µ–∫—É—â–∏—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –º–æ–¥–µ–ª–∏—Ç–µ
        
        Returns:
            –†–µ—á–Ω–∏–∫ —Å –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –ª–∏–≥–∏
        """
        try:
            log_file = self.config['log_file']
            with open(log_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.current_metrics = data.get('metrics_by_league', {})
            self.logger.info(f"üìä –ó–∞—Ä–µ–¥–µ–Ω–∏ –º–µ—Ç—Ä–∏–∫–∏ –∑–∞ {len(self.current_metrics)} –ª–∏–≥–∏")
            return self.current_metrics
            
        except FileNotFoundError:
            self.logger.warning(f"‚ùå –ù–µ –µ –Ω–∞–º–µ—Ä–µ–Ω metrics —Ñ–∞–π–ª: {self.config['log_file']}")
            return {}
        except Exception as e:
            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∑–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ –º–µ—Ç—Ä–∏–∫–∏: {e}")
            return {}
    
    def load_metrics_history(self) -> Dict:
        """
        –ó–∞—Ä–µ–∂–¥–∞ –∏—Å—Ç–æ—Ä–∏—è—Ç–∞ –Ω–∞ –º–µ—Ç—Ä–∏–∫–∏—Ç–µ
        
        Returns:
            –ò—Å—Ç–æ—Ä–∏—è –Ω–∞ –º–µ—Ç—Ä–∏–∫–∏—Ç–µ
        """
        history_file = "logs/adaptive_learning_history.json"
        
        try:
            with open(history_file, 'r', encoding='utf-8') as f:
                self.metrics_history = json.load(f)
            self.logger.info(f"üìà –ó–∞—Ä–µ–¥–µ–Ω–∞ –∏—Å—Ç–æ—Ä–∏—è –∑–∞ {len(self.metrics_history)} –∑–∞–ø–∏—Å–∞")
        except FileNotFoundError:
            self.logger.info("üìà –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –Ω–æ–≤–∞ –∏—Å—Ç–æ—Ä–∏—è –Ω–∞ –º–µ—Ç—Ä–∏–∫–∏—Ç–µ")
            self.metrics_history = {}
        except Exception as e:
            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∑–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—è: {e}")
            self.metrics_history = {}
        
        return self.metrics_history
    
    def save_metrics_history(self):
        """–ó–∞–ø–∞–∑–≤–∞ –∏—Å—Ç–æ—Ä–∏—è—Ç–∞ –Ω–∞ –º–µ—Ç—Ä–∏–∫–∏—Ç–µ"""
        history_file = "logs/adaptive_learning_history.json"
        
        try:
            # –î–æ–±–∞–≤—è —Ç–µ–∫—É—â–∏—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ –∫—ä–º –∏—Å—Ç–æ—Ä–∏—è—Ç–∞
            timestamp = datetime.now().isoformat()
            self.metrics_history[timestamp] = {
                'metrics': self.current_metrics.copy(),
                'timestamp': timestamp
            }
            
            # –ü–∞–∑–∏ —Å–∞–º–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ç–µ 30 –∑–∞–ø–∏—Å–∞
            if len(self.metrics_history) > 30:
                sorted_keys = sorted(self.metrics_history.keys())
                for old_key in sorted_keys[:-30]:
                    del self.metrics_history[old_key]
            
            os.makedirs(os.path.dirname(history_file), exist_ok=True)
            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump(self.metrics_history, f, indent=2, ensure_ascii=False)
            
            self.logger.info("üíæ –ò—Å—Ç–æ—Ä–∏—è –Ω–∞ –º–µ—Ç—Ä–∏–∫–∏—Ç–µ –∑–∞–ø–∞–∑–µ–Ω–∞")
            
        except Exception as e:
            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∑–∞–ø–∞–∑–≤–∞–Ω–µ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—è: {e}")
    
    def detect_drift(self) -> List[str]:
        """
        –û—Ç–∫—Ä–∏–≤–∞ drift –≤ per-league –º–æ–¥–µ–ª–∏—Ç–µ
        
        Returns:
            –°–ø–∏—Å—ä–∫ —Å –ª–∏–≥–∏, –∫–æ–∏—Ç–æ –∏–º–∞—Ç drift
        """
        if not self.config['enabled']:
            self.logger.info("üîí Adaptive learning –µ –∏–∑–∫–ª—é—á–µ–Ω")
            return []
        
        self.logger.info("üîç –ó–∞–ø–æ—á–≤–∞–Ω–µ –Ω–∞ drift detection...")
        
        # –ó–∞—Ä–µ–∂–¥–∞ —Ç–µ–∫—É—â–∏ –∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏ –º–µ—Ç—Ä–∏–∫–∏
        current = self.load_current_metrics()
        history = self.load_metrics_history()
        
        if not current:
            self.logger.warning("‚ùå –ù—è–º–∞ —Ç–µ–∫—É—â–∏ –º–µ—Ç—Ä–∏–∫–∏ –∑–∞ –∞–Ω–∞–ª–∏–∑")
            return []
        
        if not history:
            self.logger.info("üìä –ù—è–º–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏ –¥–∞–Ω–Ω–∏ - –∑–∞–ø–∞–∑–≤–∞–Ω–µ –Ω–∞ —Ç–µ–∫—É—â–∏—Ç–µ –º–µ—Ç—Ä–∏–∫–∏")
            self.save_metrics_history()
            return []
        
        # –ù–∞–º–∏—Ä–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ç–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏ –º–µ—Ç—Ä–∏–∫–∏
        last_timestamp = max(history.keys())
        last_metrics = history[last_timestamp]['metrics']
        
        drifted_leagues = []
        drift_threshold = self.config['drift_threshold']
        primary_metric = self.config['performance_metrics']['primary']
        
        for league_slug, current_metric in current.items():
            if league_slug not in last_metrics:
                self.logger.info(f"üÜï –ù–æ–≤–∞ –ª–∏–≥–∞: {league_slug}")
                continue
            
            last_metric = last_metrics[league_slug]
            
            # –°—Ä–∞–≤–Ω—è–≤–∞ primary –º–µ—Ç—Ä–∏–∫–∞ (log_loss)
            current_value = current_metric.get(primary_metric, 0)
            last_value = last_metric.get(primary_metric, 0)
            
            if last_value == 0:  # –ò–∑–±—è–≥–≤–∞ –¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –Ω—É–ª–∞
                continue
            
            # –ò–∑—á–∏—Å–ª—è–≤–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª–Ω–∞ –ø—Ä–æ–º—è–Ω–∞
            change = (current_value - last_value) / last_value
            
            if change > drift_threshold:
                league_name = get_league_display_name(league_slug)
                self.logger.warning(
                    f"üìâ DRIFT DETECTED: {league_name} - "
                    f"{primary_metric} –≤–ª–æ—à–µ–Ω —Å {change:.1%} "
                    f"({last_value:.3f} ‚Üí {current_value:.3f})"
                )
                drifted_leagues.append(league_slug)
            else:
                self.logger.info(
                    f"‚úÖ {get_league_display_name(league_slug)}: "
                    f"{primary_metric} –ø—Ä–æ–º—è–Ω–∞ {change:+.1%}"
                )
        
        # –ó–∞–ø–∞–∑–≤–∞ —Ç–µ–∫—É—â–∏—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ –∏—Å—Ç–æ—Ä–∏—è—Ç–∞
        self.save_metrics_history()
        
        self.logger.info(f"üîç Drift detection –∑–∞–≤—ä—Ä—à–µ–Ω: {len(drifted_leagues)} –ª–∏–≥–∏ —Å drift")
        return drifted_leagues
    
    def backup_model(self, league_slug: str) -> str:
        """
        –°—ä–∑–¥–∞–≤–∞ backup –Ω–∞ –º–æ–¥–µ–ª –∑–∞ –ª–∏–≥–∞
        
        Args:
            league_slug: Slug –Ω–∞ –ª–∏–≥–∞—Ç–∞
        
        Returns:
            –ü—ä—Ç –∫—ä–º backup –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ç–∞
        """
        try:
            # –°—ä–∑–¥–∞–≤–∞ backup –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_path = self.backup_dir / league_slug / f"ou25_backup_{timestamp}"
            backup_path.mkdir(parents=True, exist_ok=True)
            
            # –ö–æ–ø–∏—Ä–∞ –º–æ–¥–µ–ª–∞
            model_dir = get_per_league_model_path(league_slug, 'ou25', 'v1')
            
            if os.path.exists(model_dir):
                # –ö–æ–ø–∏—Ä–∞ –≤—Å–∏—á–∫–∏ —Ñ–∞–π–ª–æ–≤–µ –æ—Ç –º–æ–¥–µ–ª–∞
                for file_name in os.listdir(model_dir):
                    src = os.path.join(model_dir, file_name)
                    dst = backup_path / file_name
                    shutil.copy2(src, dst)
                
                self.logger.info(f"üíæ Backup —Å—ä–∑–¥–∞–¥–µ–Ω: {backup_path}")
                
                # –ü–æ—á–∏—Å—Ç–≤–∞ —Å—Ç–∞—Ä–∏ backup-–∏
                self._cleanup_old_backups(league_slug)
                
                return str(backup_path)
            else:
                self.logger.warning(f"‚ùå –ú–æ–¥–µ–ª –Ω–µ —Å—ä—â–µ—Å—Ç–≤—É–≤–∞: {model_dir}")
                return ""
                
        except Exception as e:
            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ backup –Ω–∞ {league_slug}: {e}")
            return ""
    
    def _cleanup_old_backups(self, league_slug: str):
        """–ü–æ—á–∏—Å—Ç–≤–∞ —Å—Ç–∞—Ä–∏ backup-–∏"""
        try:
            league_backup_dir = self.backup_dir / league_slug
            if not league_backup_dir.exists():
                return
            
            # –ù–∞–º–∏—Ä–∞ –≤—Å–∏—á–∫–∏ backup –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            backups = [d for d in league_backup_dir.iterdir() if d.is_dir() and d.name.startswith('ou25_backup_')]
            
            # –°–æ—Ä—Ç–∏—Ä–∞ –ø–æ –¥–∞—Ç–∞ (–Ω–∞–π-–Ω–æ–≤–∏—Ç–µ –ø—ä—Ä–≤–∏)
            backups.sort(key=lambda x: x.name, reverse=True)
            
            # –ò–∑—Ç—Ä–∏–≤–∞ –∏–∑–ª–∏—à–Ω–∏—Ç–µ backup-–∏
            max_backups = self.config.get('max_backups_per_league', 5)
            for old_backup in backups[max_backups:]:
                shutil.rmtree(old_backup)
                self.logger.info(f"üóëÔ∏è –ò–∑—Ç—Ä–∏—Ç —Å—Ç–∞—Ä backup: {old_backup}")
                
        except Exception as e:
            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –ø–æ—á–∏—Å—Ç–≤–∞–Ω–µ –Ω–∞ backup-–∏: {e}")
    
    def rollback_model(self, league_slug: str, backup_path: str) -> bool:
        """
        –í—ä–∑—Å—Ç–∞–Ω–æ–≤—è–≤–∞ –º–æ–¥–µ–ª –æ—Ç backup
        
        Args:
            league_slug: Slug –Ω–∞ –ª–∏–≥–∞—Ç–∞
            backup_path: –ü—ä—Ç –∫—ä–º backup-–∞
        
        Returns:
            True –∞–∫–æ rollback-—ä—Ç –µ —É—Å–ø–µ—à–µ–Ω
        """
        try:
            model_dir = get_per_league_model_path(league_slug, 'ou25', 'v1')
            backup_dir = Path(backup_path)
            
            if not backup_dir.exists():
                self.logger.error(f"‚ùå Backup –Ω–µ —Å—ä—â–µ—Å—Ç–≤—É–≤–∞: {backup_path}")
                return False
            
            # –ò–∑—Ç—Ä–∏–≤–∞ —Ç–µ–∫—É—â–∏—è –º–æ–¥–µ–ª
            if os.path.exists(model_dir):
                shutil.rmtree(model_dir)
            
            # –í—ä–∑—Å—Ç–∞–Ω–æ–≤—è–≤–∞ –æ—Ç backup
            os.makedirs(model_dir, exist_ok=True)
            for file_name in os.listdir(backup_dir):
                src = backup_dir / file_name
                dst = os.path.join(model_dir, file_name)
                shutil.copy2(src, dst)
            
            self.logger.info(f"üîÑ Rollback —É—Å–ø–µ—à–µ–Ω –∑–∞ {league_slug}")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ rollback –Ω–∞ {league_slug}: {e}")
            return False
    
    def load_new_data(self, league_slug: str, days: int = 90) -> pd.DataFrame:
        """
        –ó–∞—Ä–µ–∂–¥–∞ –Ω–æ–≤–∏ –¥–∞–Ω–Ω–∏ –∑–∞ –ª–∏–≥–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ç–µ N –¥–Ω–∏
        
        Args:
            league_slug: Slug –Ω–∞ –ª–∏–≥–∞—Ç–∞
            days: –ë—Ä–æ–π –¥–Ω–∏ –Ω–∞–∑–∞–¥
        
        Returns:
            DataFrame —Å –Ω–æ–≤–∏ –¥–∞–Ω–Ω–∏
        """
        try:
            # –ù–∞–º–∏—Ä–∞ league_id –æ—Ç slug
            league_id = None
            for lid, slug in LEAGUE_ID_TO_SLUG.items():
                if slug == league_slug:
                    league_id = lid
                    break
            
            if league_id is None:
                self.logger.error(f"‚ùå –ù–µ –µ –Ω–∞–º–µ—Ä–µ–Ω league_id –∑–∞ {league_slug}")
                return pd.DataFrame()
            
            # –ó–∞—Ä–µ–∂–¥–∞ –≤—Å–∏—á–∫–∏ –¥–∞–Ω–Ω–∏ (–≤ —Ä–µ–∞–ª–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –±–∏ –±–∏–ª–æ –æ—Ç –±–∞–∑–∞ –¥–∞–Ω–Ω–∏)
            data_files = [
                "data/processed/train_poisson_predictions.parquet",
                "data/processed/val_poisson_predictions.parquet",
                "data/processed/test_poisson_predictions.parquet"
            ]
            
            all_data = []
            for file_path in data_files:
                if os.path.exists(file_path):
                    df = pd.read_parquet(file_path)
                    all_data.append(df)
            
            if not all_data:
                self.logger.error("‚ùå –ù—è–º–∞ –Ω–∞–ª–∏—á–Ω–∏ –¥–∞–Ω–Ω–∏ —Ñ–∞–π–ª–æ–≤–µ")
                return pd.DataFrame()
            
            # –ö–æ–º–±–∏–Ω–∏—Ä–∞ –≤—Å–∏—á–∫–∏ –¥–∞–Ω–Ω–∏
            combined_df = pd.concat(all_data, ignore_index=True)
            
            # –§–∏–ª—Ç—Ä–∏—Ä–∞ –ø–æ –ª–∏–≥–∞
            league_data = combined_df[combined_df['league_id'] == league_id].copy()
            
            # –§–∏–ª—Ç—Ä–∏—Ä–∞ –ø–æ –¥–∞—Ç–∞ (–∞–∫–æ –∏–º–∞ date –∫–æ–ª–æ–Ω–∞)
            if 'date' in league_data.columns:
                cutoff_date = datetime.now() - timedelta(days=days)
                league_data['date'] = pd.to_datetime(league_data['date'], errors='coerce')
                recent_data = league_data[league_data['date'] >= cutoff_date]
            else:
                # –ê–∫–æ –Ω—è–º–∞ date –∫–æ–ª–æ–Ω–∞, –≤–∑–µ–º–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ç–µ –∑–∞–ø–∏—Å–∏
                recent_data = league_data.tail(days * 5)  # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª–Ω–æ 5 –º–∞—á–∞ –Ω–∞ –¥–µ–Ω
            
            self.logger.info(f"üìä –ó–∞—Ä–µ–¥–µ–Ω–∏ {len(recent_data)} –Ω–æ–≤–∏ –∑–∞–ø–∏—Å–∞ –∑–∞ {league_slug}")
            return recent_data
            
        except Exception as e:
            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∑–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ –¥–∞–Ω–Ω–∏ –∑–∞ {league_slug}: {e}")
            return pd.DataFrame()
    
    def retrain_league_model(self, league_slug: str) -> bool:
        """
        –ò–∑–≤—ä—Ä—à–≤–∞ incremental retraining –Ω–∞ –º–æ–¥–µ–ª –∑–∞ –ª–∏–≥–∞
        
        Args:
            league_slug: Slug –Ω–∞ –ª–∏–≥–∞—Ç–∞
        
        Returns:
            True –∞–∫–æ retraining-—ä—Ç –µ —É—Å–ø–µ—à–µ–Ω
        """
        try:
            league_name = get_league_display_name(league_slug)
            self.logger.info(f"üîÑ –ó–∞–ø–æ—á–≤–∞–Ω–µ –Ω–∞ retraining –∑–∞ {league_name}...")
            
            # 1. –°—ä–∑–¥–∞–≤–∞ backup
            backup_path = self.backup_model(league_slug)
            if not backup_path:
                self.logger.error(f"‚ùå –ù–µ—É—Å–ø–µ—à–µ–Ω backup –∑–∞ {league_slug}")
                return False
            
            # 2. –ó–∞—Ä–µ–∂–¥–∞ –Ω–æ–≤–∏ –¥–∞–Ω–Ω–∏
            new_data = self.load_new_data(
                league_slug, 
                self.config['retrain_window_days']
            )
            
            if len(new_data) < self.config['retrain_min_matches']:
                self.logger.warning(
                    f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç—ä—á–Ω–æ –Ω–æ–≤–∏ –¥–∞–Ω–Ω–∏ –∑–∞ {league_slug}: "
                    f"{len(new_data)} < {self.config['retrain_min_matches']}"
                )
                return False
            
            # 3. –ü–æ–¥–≥–æ—Ç–≤—è –¥–∞–Ω–Ω–∏ –∑–∞ –æ–±—É—á–µ–Ω–∏–µ
            feature_cols = get_feature_columns()
            
            # –ü–æ–¥–≥–æ—Ç–≤—è features
            X, _ = prepare_features(
                new_data, feature_cols, 
                use_intelligent_imputation=False, 
                legacy_fill_na=True
            )
            y = new_data['over_25'].values
            
            # Train/validation split
            validation_split = self.config.get('validation_split', 0.2)
            X_train, X_val, y_train, y_val = train_test_split(
                X, y, test_size=validation_split, 
                random_state=42, stratify=y
            )
            
            self.logger.info(
                f"üìä –î–∞–Ω–Ω–∏ –∑–∞ –æ–±—É—á–µ–Ω–∏–µ: {len(X_train)} train, {len(X_val)} val"
            )
            
            # 4. –¢—Ä–µ–Ω–∏—Ä–∞ –Ω–æ–≤ –º–æ–¥–µ–ª
            # –ò–∑–ø–æ–ª–∑–≤–∞ —Å—ä—â–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –∫–∞—Ç–æ –æ—Ä–∏–≥–∏–Ω–∞–ª–Ω–∏—è –º–æ–¥–µ–ª
            lgb_params = {
                'objective': 'binary',
                'metric': 'binary_logloss',
                'boosting_type': 'gbdt',
                'num_leaves': 31,
                'learning_rate': 0.05,
                'feature_fraction': 0.9,
                'bagging_fraction': 0.8,
                'bagging_freq': 5,
                'verbose': -1,
                'random_state': 42
            }
            
            # –°—ä–∑–¥–∞–≤–∞ LightGBM datasets
            train_data = lgb.Dataset(X_train, label=y_train)
            val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)
            
            # –¢—Ä–µ–Ω–∏—Ä–∞ –º–æ–¥–µ–ª–∞
            model = lgb.train(
                lgb_params,
                train_data,
                valid_sets=[train_data, val_data],
                valid_names=['train', 'val'],
                num_boost_round=1000,
                callbacks=[
                    lgb.early_stopping(50),
                    lgb.log_evaluation(0)  # –¢–∏—Ö —Ä–µ–∂–∏–º
                ]
            )
            
            # 5. –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ –Ω–æ–≤–∏—è –º–æ–¥–µ–ª
            y_val_pred = model.predict(X_val)
            y_val_pred_binary = (y_val_pred > 0.5).astype(int)
            
            val_metrics = evaluate_classification(
                y_val, y_val_pred_binary, y_val_pred,
                model_name=f"{league_slug}_retrained"
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–≤–∞ –¥–∞–ª–∏ –Ω–æ–≤–∏—è—Ç –º–æ–¥–µ–ª –µ –¥–æ—Å—Ç–∞—Ç—ä—á–Ω–æ –¥–æ–±—ä—Ä
            new_accuracy = val_metrics['accuracy']
            min_accuracy = self.config['performance_metrics']['accuracy_threshold']
            
            if new_accuracy < min_accuracy:
                self.logger.warning(
                    f"‚ùå –ù–æ–≤ –º–æ–¥–µ–ª –∑–∞ {league_slug} –∏–º–∞ –Ω–∏—Å—ä–∫ accuracy: "
                    f"{new_accuracy:.3f} < {min_accuracy:.3f}"
                )
                # Rollback
                if self.config.get('rollback_on_failure', True):
                    self.rollback_model(league_slug, backup_path)
                return False
            
            # 6. –ö–∞–ª–∏–±—Ä–∞—Ü–∏—è
            calibrator = IsotonicRegression(out_of_bounds='clip')
            calibrator.fit(y_val_pred, y_val)
            
            # 7. –ó–∞–ø–∞–∑–≤–∞ –Ω–æ–≤–∏—è –º–æ–¥–µ–ª
            model_dir = get_per_league_model_path(league_slug, 'ou25', 'v1')
            os.makedirs(model_dir, exist_ok=True)
            
            # –ó–∞–ø–∞–∑–≤–∞ –º–æ–¥–µ–ª–∞
            model_file = os.path.join(model_dir, 'ou25_model.pkl')
            joblib.dump(model, model_file)
            
            # –ó–∞–ø–∞–∑–≤–∞ –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä–∞
            calibrator_file = os.path.join(model_dir, 'calibrator.pkl')
            joblib.dump(calibrator, calibrator_file)
            
            # –ó–∞–ø–∞–∑–≤–∞ feature columns
            feature_file = os.path.join(model_dir, 'feature_columns.json')
            with open(feature_file, 'w') as f:
                json.dump(feature_cols, f)
            
            # –ó–∞–ø–∞–∑–≤–∞ –º–µ—Ç—Ä–∏–∫–∏
            metrics_file = os.path.join(model_dir, 'metrics.json')
            with open(metrics_file, 'w') as f:
                json.dump({
                    'retrained_at': datetime.now().isoformat(),
                    'validation_metrics': val_metrics,
                    'training_samples': len(X_train),
                    'validation_samples': len(X_val),
                    'backup_path': backup_path
                }, f, indent=2)
            
            self.logger.info(
                f"‚úÖ Retraining —É—Å–ø–µ—à–µ–Ω –∑–∞ {league_name}: "
                f"accuracy={new_accuracy:.3f}, "
                f"log_loss={val_metrics.get('log_loss', 0):.3f}"
            )
            
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ retraining –Ω–∞ {league_slug}: {e}")
            
            # Rollback –ø—Ä–∏ –≥—Ä–µ—à–∫–∞
            if self.config.get('rollback_on_failure', True) and backup_path:
                self.rollback_model(league_slug, backup_path)
            
            return False
    
    def adaptive_learning_cycle(self) -> Dict[str, Any]:
        """
        –ü—ä–ª–µ–Ω —Ü–∏–∫—ä–ª –Ω–∞ adaptive learning
        
        Returns:
            –†–µ–∑—É–ª—Ç–∞—Ç–∏ –æ—Ç —Ü–∏–∫—ä–ª–∞
        """
        if not self.config['enabled']:
            self.logger.info("üîí Adaptive learning –µ –∏–∑–∫–ª—é—á–µ–Ω")
            return {'enabled': False}
        
        self.logger.info("ü§ñ –ó–∞–ø–æ—á–≤–∞–Ω–µ –Ω–∞ adaptive learning cycle...")
        
        results = {
            'timestamp': datetime.now().isoformat(),
            'enabled': True,
            'drifted_leagues': [],
            'retrained_leagues': [],
            'failed_retrains': [],
            'summary': {}
        }
        
        try:
            # 1. Drift detection
            drifted_leagues = self.detect_drift()
            results['drifted_leagues'] = drifted_leagues
            
            if not drifted_leagues:
                self.logger.info("‚úÖ –ù—è–º–∞ –æ—Ç–∫—Ä–∏—Ç drift - –Ω—è–º–∞ –Ω—É–∂–¥–∞ –æ—Ç retraining")
                results['summary'] = {
                    'total_drifted': 0,
                    'total_retrained': 0,
                    'success_rate': 1.0
                }
                return results
            
            # 2. Retraining –∑–∞ drifted –ª–∏–≥–∏
            max_concurrent = self.config.get('max_concurrent_retrains', 2)
            
            if len(drifted_leagues) <= max_concurrent:
                # Sequential retraining –∑–∞ –º–∞–ª–∫–æ –ª–∏–≥–∏
                for league_slug in drifted_leagues:
                    success = self.retrain_league_model(league_slug)
                    if success:
                        results['retrained_leagues'].append(league_slug)
                    else:
                        results['failed_retrains'].append(league_slug)
            else:
                # Parallel retraining –∑–∞ –º–Ω–æ–≥–æ –ª–∏–≥–∏
                with ThreadPoolExecutor(max_workers=max_concurrent) as executor:
                    future_to_league = {
                        executor.submit(self.retrain_league_model, league): league
                        for league in drifted_leagues
                    }
                    
                    for future in as_completed(future_to_league):
                        league = future_to_league[future]
                        try:
                            success = future.result()
                            if success:
                                results['retrained_leagues'].append(league)
                            else:
                                results['failed_retrains'].append(league)
                        except Exception as e:
                            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ parallel retraining –Ω–∞ {league}: {e}")
                            results['failed_retrains'].append(league)
            
            # 3. Summary
            total_retrained = len(results['retrained_leagues'])
            total_failed = len(results['failed_retrains'])
            success_rate = total_retrained / len(drifted_leagues) if drifted_leagues else 1.0
            
            results['summary'] = {
                'total_drifted': len(drifted_leagues),
                'total_retrained': total_retrained,
                'total_failed': total_failed,
                'success_rate': success_rate
            }
            
            # –õ–æ–≥–≤–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ
            self.logger.info(
                f"ü§ñ Adaptive learning –∑–∞–≤—ä—Ä—à–µ–Ω: "
                f"{total_retrained}/{len(drifted_leagues)} —É—Å–ø–µ—à–Ω–∏ retraining-–∏ "
                f"(success rate: {success_rate:.1%})"
            )
            
            if results['retrained_leagues']:
                retrained_names = [get_league_display_name(l) for l in results['retrained_leagues']]
                self.logger.info(f"‚úÖ Retrained –ª–∏–≥–∏: {', '.join(retrained_names)}")
            
            if results['failed_retrains']:
                failed_names = [get_league_display_name(l) for l in results['failed_retrains']]
                self.logger.warning(f"‚ùå Failed retrains: {', '.join(failed_names)}")
            
        except Exception as e:
            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –≤ adaptive learning cycle: {e}")
            results['error'] = str(e)
        
        return results


def main():
    """–ì–ª–∞–≤–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è –∑–∞ adaptive learning"""
    logger = setup_logging()
    
    logger.info("ü§ñ –°–¢–ê–†–¢–ò–†–ê–ù–ï –ù–ê ADAPTIVE LEARNING")
    logger.info("=" * 60)
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–∞ adaptive trainer
        trainer = AdaptiveTrainer()
        
        # –°—Ç–∞—Ä—Ç–∏—Ä–∞ adaptive learning cycle
        results = trainer.adaptive_learning_cycle()
        
        # –ü–æ–∫–∞–∑–≤–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ
        print("\nü§ñ ADAPTIVE LEARNING –†–ï–ó–£–õ–¢–ê–¢–ò:")
        print("=" * 50)
        
        if not results['enabled']:
            print("üîí Adaptive learning –µ –∏–∑–∫–ª—é—á–µ–Ω")
            return
        
        summary = results.get('summary', {})
        print(f"üìä –û–±—â–æ –ª–∏–≥–∏ —Å drift: {summary.get('total_drifted', 0)}")
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–∏ retraining-–∏: {summary.get('total_retrained', 0)}")
        print(f"‚ùå –ù–µ—É—Å–ø–µ—à–Ω–∏ retraining-–∏: {summary.get('total_failed', 0)}")
        print(f"üìà Success rate: {summary.get('success_rate', 0):.1%}")
        
        if results.get('retrained_leagues'):
            print(f"\nüîÑ Retrained –ª–∏–≥–∏:")
            for league_slug in results['retrained_leagues']:
                print(f"   ‚úÖ {get_league_display_name(league_slug)}")
        
        if results.get('failed_retrains'):
            print(f"\n‚ùå Failed retrains:")
            for league_slug in results['failed_retrains']:
                print(f"   ‚ùå {get_league_display_name(league_slug)}")
        
        # –ó–∞–ø–∞–∑–≤–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ
        results_file = "logs/adaptive_learning_results.json"
        os.makedirs(os.path.dirname(results_file), exist_ok=True)
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"üíæ –†–µ–∑—É–ª—Ç–∞—Ç–∏ –∑–∞–ø–∞–∑–µ–Ω–∏ –≤ {results_file}")
        logger.info("‚úÖ Adaptive learning –∑–∞–≤—ä—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        
    except Exception as e:
        logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –≤ adaptive learning: {e}")
        raise


if __name__ == "__main__":
    main()
