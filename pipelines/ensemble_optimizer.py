#!/usr/bin/env python3
"""
Dynamic Ensemble Optimizer –∑–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω–µ –Ω–∞ ensemble weights

–ê–Ω–∞–ª–∏–∑–∏—Ä–∞ production —Ä–µ–∑—É–ª—Ç–∞—Ç–∏ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –∫–æ—Ä–∏–≥–∏—Ä–∞ —Ç–µ–≥–ª–∞—Ç–∞ –º–µ–∂–¥—É
Poisson, ML –∏ Elo –º–æ–¥–µ–ª–∏—Ç–µ –∑–∞ –ø–æ–¥–æ–±—Ä—è–≤–∞–Ω–µ –Ω–∞ ensemble performance.
"""

import sys
import os
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

import json
import pandas as pd
import numpy as np
import yaml
import shutil
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Any
import logging
from scipy.optimize import minimize
from sklearn.model_selection import KFold
from sklearn.metrics import log_loss, brier_score_loss, accuracy_score
import warnings

from core.utils import setup_logging


class EnsembleOptimizer:
    """
    Dynamic Ensemble Optimizer –∑–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω–µ –Ω–∞ weights
    """
    
    def __init__(self, config_path: str = "config/ensemble_weights.yaml"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ EnsembleOptimizer
        
        Args:
            config_path: –ü—ä—Ç –∫—ä–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–∏—è —Ñ–∞–π–ª
        """
        self.config_path = config_path
        self.config = self._load_config()
        self.logger = self._setup_logging()
        
        # –¢–µ–∫—É—â–∏ —Ç–µ–≥–ª–∞
        self.current_weights = self.config['ensemble']['current_weights'].copy()
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        self.opt_config = self.config['ensemble']['optimization']
        
        # Backup –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
        self.backup_dir = Path(self.config['ensemble']['backup']['backup_dir'])
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        
        self.logger.info("üéØ EnsembleOptimizer –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω")
    
    def _load_config(self) -> Dict:
        """–ó–∞—Ä–µ–∂–¥–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è—Ç–∞"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except Exception as e:
            # Fallback –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
            return {
                'ensemble': {
                    'current_weights': {'poisson': 0.30, 'ml': 0.50, 'elo': 0.20},
                    'optimization': {
                        'enabled': True,
                        'min_improvement': 0.02,
                        'lookback_days': 45,
                        'weight_constraints': {'min_weight': 0.1, 'max_weight': 0.8},
                        'cross_validation_folds': 5,
                        'validation_threshold': 0.01
                    },
                    'backup': {
                        'enabled': True,
                        'max_backups': 10,
                        'backup_dir': 'config/backups/'
                    },
                    'logging': {
                        'enabled': True,
                        'log_file': 'logs/ensemble_optimizer.log'
                    },
                    'history': {
                        'optimization_count': 0
                    }
                }
            }
    
    def _setup_logging(self) -> logging.Logger:
        """–ù–∞—Å—Ç—Ä–æ–π–≤–∞ logging –∑–∞ ensemble optimizer"""
        logger = setup_logging()
        
        # –î–æ–±–∞–≤—è file handler –∑–∞ ensemble optimizer
        log_config = self.config['ensemble'].get('logging', {})
        log_file = log_config.get('log_file', 'logs/ensemble_optimizer.log')
        
        os.makedirs(os.path.dirname(log_file), exist_ok=True)
        
        file_handler = logging.FileHandler(log_file)
        file_handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
        
        return logger
    
    def load_historical_predictions(self, days: int = None) -> pd.DataFrame:
        """
        –ó–∞—Ä–µ–∂–¥–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏ –∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏
        
        Args:
            days: –ë—Ä–æ–π –¥–Ω–∏ –Ω–∞–∑–∞–¥ (–ø–æ –ø–æ–¥—Ä–∞–∑–±–∏—Ä–∞–Ω–µ –æ—Ç config)
        
        Returns:
            DataFrame —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏ –¥–∞–Ω–Ω–∏
        """
        if days is None:
            days = self.opt_config['lookback_days']
        
        try:
            # –ü—ä—Ç—è –∫—ä–º prediction history —Ñ–∞–π–ª–∞
            history_file = "logs/predictions_history/ou25_predictions.jsonl"
            
            if not os.path.exists(history_file):
                self.logger.warning(f"‚ùå –ù–µ –µ –Ω–∞–º–µ—Ä–µ–Ω history —Ñ–∞–π–ª: {history_file}")
                return pd.DataFrame()
            
            # –ó–∞—Ä–µ–∂–¥–∞ JSONL —Ñ–∞–π–ª–∞
            predictions = []
            cutoff_date = datetime.now() - timedelta(days=days)
            
            with open(history_file, 'r', encoding='utf-8') as f:
                for line in f:
                    try:
                        data = json.loads(line.strip())
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–≤–∞ –¥–∞—Ç–∞
                        pred_date = datetime.fromisoformat(data.get('timestamp', ''))
                        if pred_date >= cutoff_date:
                            predictions.append(data)
                            
                    except (json.JSONDecodeError, ValueError) as e:
                        continue
            
            if not predictions:
                self.logger.warning(f"‚ùå –ù—è–º–∞ –Ω–∞–ª–∏—á–Ω–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ç–µ {days} –¥–Ω–∏")
                return pd.DataFrame()
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞ –≤ DataFrame
            df = pd.DataFrame(predictions)
            
            # –§–∏–ª—Ç—Ä–∏—Ä–∞ —Å–∞–º–æ –∑–∞–ø–∏—Å–∏ —Å —Ä–µ–∞–ª–Ω–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏
            df = df[df['actual_result'].notna()].copy()
            
            self.logger.info(f"üìä –ó–∞—Ä–µ–¥–µ–Ω–∏ {len(df)} –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏ –∑–∞ {days} –¥–Ω–∏")
            return df
            
        except Exception as e:
            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∑–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏ –¥–∞–Ω–Ω–∏: {e}")
            return pd.DataFrame()
    
    def evaluate_component_performance(self, df: pd.DataFrame) -> Dict[str, Dict[str, float]]:
        """
        –û—Ü–µ–Ω—è–≤–∞ performance –Ω–∞ –æ—Ç–¥–µ–ª–Ω–∏—Ç–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏
        
        Args:
            df: DataFrame —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏ –¥–∞–Ω–Ω–∏
        
        Returns:
            –ú–µ—Ç—Ä–∏–∫–∏ –∑–∞ –≤—Å–µ–∫–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
        """
        if df.empty:
            return {}
        
        try:
            results = {}
            
            # –ò–∑–≤–ª–∏—á–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–Ω–∏—Ç–µ –ø—Ä–æ–≥–Ω–æ–∑–∏ –∏ —Ä–µ–∞–ª–Ω–∏—Ç–µ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏
            y_true = df['actual_result'].values
            
            components = ['poisson', 'ml', 'elo']
            
            for component in components:
                if f'{component}_prediction' not in df.columns:
                    self.logger.warning(f"‚ö†Ô∏è –õ–∏–ø—Å–≤–∞ {component}_prediction –≤ –¥–∞–Ω–Ω–∏—Ç–µ")
                    continue
                
                y_pred = df[f'{component}_prediction'].values
                
                # –ü—Ä–æ–≤–µ—Ä—è–≤–∞ –∑–∞ –≤–∞–ª–∏–¥–Ω–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏
                if len(y_pred) == 0 or np.any(np.isnan(y_pred)):
                    self.logger.warning(f"‚ö†Ô∏è –ù–µ–≤–∞–ª–∏–¥–Ω–∏ –¥–∞–Ω–Ω–∏ –∑–∞ {component}")
                    continue
                
                # Clipping –∑–∞ log_loss
                y_pred_clipped = np.clip(y_pred, 1e-15, 1 - 1e-15)
                
                # –ò–∑—á–∏—Å–ª—è–≤–∞ –º–µ—Ç—Ä–∏–∫–∏
                try:
                    ll = log_loss(y_true, y_pred_clipped)
                    bs = brier_score_loss(y_true, y_pred)
                    acc = accuracy_score(y_true, (y_pred > 0.5).astype(int))
                    
                    results[component] = {
                        'log_loss': ll,
                        'brier_score': bs,
                        'accuracy': acc,
                        'samples': len(y_pred)
                    }
                    
                    self.logger.info(
                        f"üìà {component.upper()}: "
                        f"log_loss={ll:.4f}, brier_score={bs:.4f}, accuracy={acc:.3f}"
                    )
                    
                except Exception as e:
                    self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∏–∑—á–∏—Å–ª—è–≤–∞–Ω–µ –Ω–∞ –º–µ—Ç—Ä–∏–∫–∏ –∑–∞ {component}: {e}")
                    continue
            
            return results
            
        except Exception as e:
            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏—Ç–µ: {e}")
            return {}
    
    def _ensemble_predictions(self, df: pd.DataFrame, weights: Dict[str, float]) -> np.ndarray:
        """
        –ò–∑—á–∏—Å–ª—è–≤–∞ ensemble –ø—Ä–æ–≥–Ω–æ–∑–∏ —Å –¥–∞–¥–µ–Ω–∏ —Ç–µ–≥–ª–∞
        
        Args:
            df: DataFrame —Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–Ω–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏
            weights: –¢–µ–≥–ª–∞ –∑–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏—Ç–µ
        
        Returns:
            Ensemble –ø—Ä–æ–≥–Ω–æ–∑–∏
        """
        ensemble_pred = np.zeros(len(df))
        
        for component, weight in weights.items():
            if f'{component}_prediction' in df.columns:
                component_pred = df[f'{component}_prediction'].values
                ensemble_pred += weight * component_pred
        
        return ensemble_pred
    
    def _objective_function(self, weights_array: np.ndarray, df: pd.DataFrame, 
                          components: List[str]) -> float:
        """
        Objective function –∑–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (–º–∏–Ω–∏–º–∏–∑–∏—Ä–∞ log_loss)
        
        Args:
            weights_array: –¢–µ–≥–ª–∞ –∫–∞—Ç–æ numpy array
            df: DataFrame —Å –¥–∞–Ω–Ω–∏
            components: –°–ø–∏—Å—ä–∫ —Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏
        
        Returns:
            Log loss —Å—Ç–æ–π–Ω–æ—Å—Ç
        """
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞ array –≤ dict
        weights = dict(zip(components, weights_array))
        
        # –ò–∑—á–∏—Å–ª—è–≤–∞ ensemble –ø—Ä–æ–≥–Ω–æ–∑–∏
        y_pred = self._ensemble_predictions(df, weights)
        y_true = df['actual_result'].values
        
        # Clipping –∑–∞ log_loss
        y_pred_clipped = np.clip(y_pred, 1e-15, 1 - 1e-15)
        
        try:
            return log_loss(y_true, y_pred_clipped)
        except Exception:
            return float('inf')
    
    def optimize_weights(self, df: pd.DataFrame) -> Tuple[Dict[str, float], Dict[str, float]]:
        """
        –û–ø—Ç–∏–º–∏–∑–∏—Ä–∞ ensemble —Ç–µ–≥–ª–∞—Ç–∞
        
        Args:
            df: DataFrame —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏ –¥–∞–Ω–Ω–∏
        
        Returns:
            Tuple –æ—Ç (–Ω–æ–≤–∏ —Ç–µ–≥–ª–∞, –º–µ—Ç—Ä–∏–∫–∏)
        """
        if df.empty:
            self.logger.warning("‚ùå –ù—è–º–∞ –¥–∞–Ω–Ω–∏ –∑–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è")
            return self.current_weights, {}
        
        try:
            # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ –∑–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
            available_components = []
            for comp in ['poisson', 'ml', 'elo']:
                if f'{comp}_prediction' in df.columns:
                    available_components.append(comp)
            
            if len(available_components) < 2:
                self.logger.warning("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç—ä—á–Ω–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ –∑–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è")
                return self.current_weights, {}
            
            self.logger.info(f"üéØ –û–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω–µ –Ω–∞ —Ç–µ–≥–ª–∞ –∑–∞: {available_components}")
            
            # –¢–µ–∫—É—â–∏ —Ç–µ–≥–ª–∞ –∫–∞—Ç–æ starting point
            initial_weights = np.array([
                self.current_weights.get(comp, 1.0/len(available_components)) 
                for comp in available_components
            ])
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∏—Ä–∞ –Ω–∞—á–∞–ª–Ω–∏—Ç–µ —Ç–µ–≥–ª–∞
            initial_weights = initial_weights / initial_weights.sum()
            
            # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
            min_weight = self.opt_config['weight_constraints']['min_weight']
            max_weight = self.opt_config['weight_constraints']['max_weight']
            
            bounds = [(min_weight, max_weight) for _ in available_components]
            
            # Constraint: —Å—É–º–∞—Ç–∞ –Ω–∞ —Ç–µ–≥–ª–∞—Ç–∞ = 1
            constraints = {'type': 'eq', 'fun': lambda x: np.sum(x) - 1.0}
            
            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å scipy
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                
                result = minimize(
                    self._objective_function,
                    initial_weights,
                    args=(df, available_components),
                    method='SLSQP',
                    bounds=bounds,
                    constraints=constraints,
                    options={
                        'maxiter': self.opt_config.get('max_iterations', 1000),
                        'ftol': self.opt_config.get('tolerance', 1e-6)
                    }
                )
            
            if not result.success:
                self.logger.warning(f"‚ö†Ô∏è –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è—Ç–∞ –Ω–µ –∫–æ–Ω–≤–µ—Ä–≥–∏—Ä–∞: {result.message}")
                return self.current_weights, {}
            
            # –ù–æ–≤–∏ —Ç–µ–≥–ª–∞
            new_weights_array = result.x
            new_weights = dict(zip(available_components, new_weights_array))
            
            # –î–æ–±–∞–≤—è –ª–∏–ø—Å–≤–∞—â–∏—Ç–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ —Å 0 —Ç–µ–≥–ª–æ
            for comp in ['poisson', 'ml', 'elo']:
                if comp not in new_weights:
                    new_weights[comp] = 0.0
            
            # –ò–∑—á–∏—Å–ª—è–≤–∞ –º–µ—Ç—Ä–∏–∫–∏
            current_loss = self._objective_function(initial_weights, df, available_components)
            new_loss = result.fun
            
            improvement = (current_loss - new_loss) / current_loss
            
            metrics = {
                'current_log_loss': current_loss,
                'new_log_loss': new_loss,
                'improvement': improvement,
                'optimization_success': result.success,
                'iterations': result.nit if hasattr(result, 'nit') else 0
            }
            
            self.logger.info(
                f"üéØ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤—ä—Ä—à–µ–Ω–∞: "
                f"log_loss {current_loss:.4f} ‚Üí {new_loss:.4f} "
                f"(–ø–æ–¥–æ–±—Ä–µ–Ω–∏–µ: {improvement:.1%})"
            )
            
            return new_weights, metrics
            
        except Exception as e:
            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–∞ —Ç–µ–≥–ª–∞: {e}")
            return self.current_weights, {}
    
    def validate_new_weights(self, df: pd.DataFrame, new_weights: Dict[str, float], 
                           metrics: Dict[str, float]) -> bool:
        """
        –í–∞–ª–∏–¥–∏—Ä–∞ –Ω–æ–≤–∏—Ç–µ —Ç–µ–≥–ª–∞
        
        Args:
            df: DataFrame —Å –¥–∞–Ω–Ω–∏
            new_weights: –ù–æ–≤–∏ —Ç–µ–≥–ª–∞
            metrics: –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è—Ç–∞
        
        Returns:
            True –∞–∫–æ —Ç–µ–≥–ª–∞—Ç–∞ —Å–∞ –≤–∞–ª–∏–¥–Ω–∏
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–≤–∞ –º–∏–Ω–∏–º–∞–ª–Ω–æ—Ç–æ –ø–æ–¥–æ–±—Ä–µ–Ω–∏–µ
            min_improvement = self.opt_config['min_improvement']
            improvement = metrics.get('improvement', 0)
            
            if improvement < min_improvement:
                self.logger.info(
                    f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç—ä—á–Ω–æ –ø–æ–¥–æ–±—Ä–µ–Ω–∏–µ: {improvement:.1%} < {min_improvement:.1%}"
                )
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–≤–∞ —Å—É–º–∞—Ç–∞ –Ω–∞ —Ç–µ–≥–ª–∞—Ç–∞
            weights_sum = sum(new_weights.values())
            if abs(weights_sum - 1.0) > 1e-6:
                self.logger.warning(f"‚ö†Ô∏è –ù–µ–≤–∞–ª–∏–¥–Ω–∞ —Å—É–º–∞ –Ω–∞ —Ç–µ–≥–ª–∞: {weights_sum:.6f}")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–≤–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è—Ç–∞
            min_weight = self.opt_config['weight_constraints']['min_weight']
            max_weight = self.opt_config['weight_constraints']['max_weight']
            
            for component, weight in new_weights.items():
                if weight > 0 and (weight < min_weight or weight > max_weight):
                    self.logger.warning(
                        f"‚ö†Ô∏è –¢–µ–≥–ª–æ –∑–∞ {component} –∏–∑–≤—ä–Ω –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è—Ç–∞: {weight:.3f}"
                    )
                    return False
            
            # Cross-validation –∞–∫–æ –∏–º–∞ –¥–æ—Å—Ç–∞—Ç—ä—á–Ω–æ –¥–∞–Ω–Ω–∏
            if len(df) >= 100:
                cv_valid = self._cross_validate_weights(df, new_weights)
                if not cv_valid:
                    return False
            
            self.logger.info("‚úÖ –ù–æ–≤–∏—Ç–µ —Ç–µ–≥–ª–∞ —Å–∞ –≤–∞–ª–∏–¥–Ω–∏")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ —Ç–µ–≥–ª–∞: {e}")
            return False
    
    def _cross_validate_weights(self, df: pd.DataFrame, weights: Dict[str, float]) -> bool:
        """
        Cross-validation –Ω–∞ –Ω–æ–≤–∏—Ç–µ —Ç–µ–≥–ª–∞
        
        Args:
            df: DataFrame —Å –¥–∞–Ω–Ω–∏
            weights: –¢–µ–≥–ª–∞ –∑–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—è
        
        Returns:
            True –∞–∫–æ CV –µ —É—Å–ø–µ—à–Ω–∞
        """
        try:
            n_folds = self.opt_config.get('cross_validation_folds', 5)
            kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)
            
            cv_scores = []
            
            for train_idx, val_idx in kf.split(df):
                train_df = df.iloc[train_idx]
                val_df = df.iloc[val_idx]
                
                # Ensemble –ø—Ä–æ–≥–Ω–æ–∑–∏ –∑–∞ validation set
                val_pred = self._ensemble_predictions(val_df, weights)
                val_true = val_df['actual_result'].values
                
                # Log loss –∑–∞ validation
                val_pred_clipped = np.clip(val_pred, 1e-15, 1 - 1e-15)
                cv_score = log_loss(val_true, val_pred_clipped)
                cv_scores.append(cv_score)
            
            mean_cv_score = np.mean(cv_scores)
            std_cv_score = np.std(cv_scores)
            
            # –°—Ä–∞–≤–Ω—è–≤–∞ —Å —Ç–µ–∫—É—â–∏—Ç–µ —Ç–µ–≥–ª–∞
            current_pred = self._ensemble_predictions(df, self.current_weights)
            current_true = df['actual_result'].values
            current_pred_clipped = np.clip(current_pred, 1e-15, 1 - 1e-15)
            current_score = log_loss(current_true, current_pred_clipped)
            
            improvement = (current_score - mean_cv_score) / current_score
            validation_threshold = self.opt_config.get('validation_threshold', 0.01)
            
            if improvement >= validation_threshold:
                self.logger.info(
                    f"‚úÖ CV –≤–∞–ª–∏–¥–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞: {improvement:.1%} –ø–æ–¥–æ–±—Ä–µ–Ω–∏–µ "
                    f"(CV score: {mean_cv_score:.4f} ¬± {std_cv_score:.4f})"
                )
                return True
            else:
                self.logger.warning(
                    f"‚ùå CV –≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–µ—É—Å–ø–µ—à–Ω–∞: {improvement:.1%} –ø–æ–¥–æ–±—Ä–µ–Ω–∏–µ "
                    f"< {validation_threshold:.1%}"
                )
                return False
                
        except Exception as e:
            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ CV –≤–∞–ª–∏–¥–∞—Ü–∏—è: {e}")
            return False
    
    def backup_old_weights(self) -> str:
        """
        –°—ä–∑–¥–∞–≤–∞ backup –Ω–∞ —Ç–µ–∫—É—â–∏—Ç–µ —Ç–µ–≥–ª–∞
        
        Returns:
            –ü—ä—Ç –∫—ä–º backup —Ñ–∞–π–ª–∞
        """
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_filename = f"ensemble_weights_{timestamp}.yaml"
            backup_path = self.backup_dir / backup_filename
            
            # –ö–æ–ø–∏—Ä–∞ —Ç–µ–∫—É—â–∏—è config —Ñ–∞–π–ª
            shutil.copy2(self.config_path, backup_path)
            
            self.logger.info(f"üíæ Backup —Å—ä–∑–¥–∞–¥–µ–Ω: {backup_path}")
            
            # –ü–æ—á–∏—Å—Ç–≤–∞ —Å—Ç–∞—Ä–∏ backup-–∏
            self._cleanup_old_backups()
            
            return str(backup_path)
            
        except Exception as e:
            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ —Å—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ backup: {e}")
            return ""
    
    def _cleanup_old_backups(self):
        """–ü–æ—á–∏—Å—Ç–≤–∞ —Å—Ç–∞—Ä–∏ backup —Ñ–∞–π–ª–æ–≤–µ"""
        try:
            max_backups = self.config['ensemble']['backup'].get('max_backups', 10)
            
            # –ù–∞–º–∏—Ä–∞ –≤—Å–∏—á–∫–∏ backup —Ñ–∞–π–ª–æ–≤–µ
            backup_files = list(self.backup_dir.glob("ensemble_weights_*.yaml"))
            
            # –°–æ—Ä—Ç–∏—Ä–∞ –ø–æ –¥–∞—Ç–∞ (–Ω–∞–π-–Ω–æ–≤–∏—Ç–µ –ø—ä—Ä–≤–∏)
            backup_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            
            # –ò–∑—Ç—Ä–∏–≤–∞ –∏–∑–ª–∏—à–Ω–∏—Ç–µ backup-–∏
            for old_backup in backup_files[max_backups:]:
                old_backup.unlink()
                self.logger.info(f"üóëÔ∏è –ò–∑—Ç—Ä–∏—Ç —Å—Ç–∞—Ä backup: {old_backup}")
                
        except Exception as e:
            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –ø–æ—á–∏—Å—Ç–≤–∞–Ω–µ –Ω–∞ backup-–∏: {e}")
    
    def update_weights_config(self, new_weights: Dict[str, float], 
                            metrics: Dict[str, float], backup_path: str):
        """
        –û–±–Ω–æ–≤—è–≤–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è—Ç–∞ —Å –Ω–æ–≤–∏—Ç–µ —Ç–µ–≥–ª–∞
        
        Args:
            new_weights: –ù–æ–≤–∏ —Ç–µ–≥–ª–∞
            metrics: –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è—Ç–∞
            backup_path: –ü—ä—Ç –∫—ä–º backup —Ñ–∞–π–ª–∞
        """
        try:
            # –û–±–Ω–æ–≤—è–≤–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è—Ç–∞
            self.config['ensemble']['current_weights'] = new_weights.copy()
            
            # –û–±–Ω–æ–≤—è–≤–∞ –∏—Å—Ç–æ—Ä–∏—è—Ç–∞
            self.config['ensemble']['history']['last_optimization'] = datetime.now().isoformat()
            self.config['ensemble']['history']['last_weights_update'] = datetime.now().isoformat()
            self.config['ensemble']['history']['optimization_count'] = \
                self.config['ensemble']['history'].get('optimization_count', 0) + 1
            
            # –î–æ–±–∞–≤—è –º–µ—Ç—Ä–∏–∫–∏
            self.config['ensemble']['last_optimization_metrics'] = {
                'timestamp': datetime.now().isoformat(),
                'metrics': metrics,
                'backup_path': backup_path,
                'old_weights': self.current_weights.copy(),
                'new_weights': new_weights.copy()
            }
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞ numpy —Ç–∏–ø–æ–≤–µ –ø—Ä–µ–¥–∏ –∑–∞–ø–∏—Å
            def convert_numpy_types(obj):
                """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞ numpy —Ç–∏–ø–æ–≤–µ –≤ Python —Ç–∏–ø–æ–≤–µ"""
                if isinstance(obj, np.bool_):
                    return bool(obj)
                elif isinstance(obj, np.integer):
                    return int(obj)
                elif isinstance(obj, np.floating):
                    return float(obj)
                elif isinstance(obj, dict):
                    return {k: convert_numpy_types(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [convert_numpy_types(item) for item in obj]
                return obj
            
            config_to_save = convert_numpy_types(self.config)
            
            # –ó–∞–ø–∏—Å–≤–∞ –æ–±–Ω–æ–≤–µ–Ω–∞—Ç–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
            with open(self.config_path, 'w', encoding='utf-8') as f:
                yaml.dump(config_to_save, f, default_flow_style=False, allow_unicode=True)
            
            # –û–±–Ω–æ–≤—è–≤–∞ —Ç–µ–∫—É—â–∏—Ç–µ —Ç–µ–≥–ª–∞
            self.current_weights = new_weights.copy()
            
            self.logger.info("üíæ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è—Ç–∞ –µ –æ–±–Ω–æ–≤–µ–Ω–∞ —Å –Ω–æ–≤–∏—Ç–µ —Ç–µ–≥–ª–∞")
            
            # –õ–æ–≥–≤–∞ –ø—Ä–æ–º–µ–Ω–∏—Ç–µ
            for component, weight in new_weights.items():
                old_weight = self.current_weights.get(component, 0)
                change = weight - old_weight
                self.logger.info(f"üîÑ {component}: {old_weight:.3f} ‚Üí {weight:.3f} ({change:+.3f})")
            
        except Exception as e:
            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤—è–≤–∞–Ω–µ –Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è—Ç–∞: {e}")
    
    def optimize_ensemble_weights(self) -> Dict[str, Any]:
        """
        –ü—ä–ª–µ–Ω —Ü–∏–∫—ä–ª –Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–∞ ensemble —Ç–µ–≥–ª–∞
        
        Returns:
            –†–µ–∑—É–ª—Ç–∞—Ç–∏ –æ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è—Ç–∞
        """
        if not self.opt_config.get('enabled', True):
            self.logger.info("üîí Ensemble optimization –µ –∏–∑–∫–ª—é—á–µ–Ω–∞")
            return {'enabled': False}
        
        self.logger.info("üéØ –ó–∞–ø–æ—á–≤–∞–Ω–µ –Ω–∞ ensemble weights optimization...")
        
        results = {
            'timestamp': datetime.now().isoformat(),
            'enabled': True,
            'success': False,
            'weights_updated': False,
            'old_weights': self.current_weights.copy(),
            'new_weights': {},
            'metrics': {},
            'backup_path': ''
        }
        
        try:
            # 1. –ó–∞—Ä–µ–∂–¥–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏ –¥–∞–Ω–Ω–∏
            df = self.load_historical_predictions()
            
            if df.empty:
                self.logger.warning("‚ùå –ù—è–º–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏ –¥–∞–Ω–Ω–∏ –∑–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è")
                results['error'] = 'No historical data'
                return results
            
            # 2. –û—Ü–µ–Ω—è–≤–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏—Ç–µ
            component_performance = self.evaluate_component_performance(df)
            results['component_performance'] = component_performance
            
            # 3. –û–ø—Ç–∏–º–∏–∑–∏—Ä–∞ —Ç–µ–≥–ª–∞—Ç–∞
            new_weights, opt_metrics = self.optimize_weights(df)
            results['new_weights'] = new_weights
            results['metrics'] = opt_metrics
            
            if not opt_metrics:
                self.logger.warning("‚ùå –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è—Ç–∞ —Å–µ –ø—Ä–æ–≤–∞–ª–∏")
                results['error'] = 'Optimization failed'
                return results
            
            # 4. –í–∞–ª–∏–¥–∏—Ä–∞ –Ω–æ–≤–∏—Ç–µ —Ç–µ–≥–ª–∞
            if not self.validate_new_weights(df, new_weights, opt_metrics):
                self.logger.info("‚ùå –ù–æ–≤–∏—Ç–µ —Ç–µ–≥–ª–∞ –Ω–µ –ø—Ä–µ–º–∏–Ω–∞—Ö–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—è—Ç–∞")
                results['error'] = 'Validation failed'
                return results
            
            # 5. –°—ä–∑–¥–∞–≤–∞ backup
            backup_path = self.backup_old_weights()
            results['backup_path'] = backup_path
            
            # 6. –û–±–Ω–æ–≤—è–≤–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è—Ç–∞
            self.update_weights_config(new_weights, opt_metrics, backup_path)
            
            results['success'] = True
            results['weights_updated'] = True
            
            improvement = opt_metrics.get('improvement', 0)
            self.logger.info(
                f"‚úÖ Ensemble optimization –∑–∞–≤—ä—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ: "
                f"{improvement:.1%} –ø–æ–¥–æ–±—Ä–µ–Ω–∏–µ –≤ log_loss"
            )
            
        except Exception as e:
            self.logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –≤ ensemble optimization: {e}")
            results['error'] = str(e)
        
        return results


def optimize_ensemble_weights() -> Dict[str, Any]:
    """
    Convenience —Ñ—É–Ω–∫—Ü–∏—è –∑–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–∞ ensemble —Ç–µ–≥–ª–∞
    
    Returns:
        –†–µ–∑—É–ª—Ç–∞—Ç–∏ –æ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è—Ç–∞
    """
    optimizer = EnsembleOptimizer()
    return optimizer.optimize_ensemble_weights()


def main():
    """–ì–ª–∞–≤–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è –∑–∞ ensemble optimization"""
    logger = setup_logging()
    
    logger.info("üéØ –°–¢–ê–†–¢–ò–†–ê–ù–ï –ù–ê ENSEMBLE WEIGHTS OPTIMIZATION")
    logger.info("=" * 70)
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–∞ optimizer
        optimizer = EnsembleOptimizer()
        
        # –°—Ç–∞—Ä—Ç–∏—Ä–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
        results = optimizer.optimize_ensemble_weights()
        
        # –ü–æ–∫–∞–∑–≤–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ
        print("\nüéØ ENSEMBLE OPTIMIZATION –†–ï–ó–£–õ–¢–ê–¢–ò:")
        print("=" * 60)
        
        if not results['enabled']:
            print("üîí Ensemble optimization –µ –∏–∑–∫–ª—é—á–µ–Ω–∞")
            return
        
        if results['success']:
            print("‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è—Ç–∞ –∑–∞–≤—ä—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            
            if results['weights_updated']:
                print("\nüîÑ –ü–†–û–ú–ï–ù–ò –í –¢–ï–ì–õ–ê–¢–ê:")
                old_weights = results['old_weights']
                new_weights = results['new_weights']
                
                for component in ['poisson', 'ml', 'elo']:
                    old_w = old_weights.get(component, 0)
                    new_w = new_weights.get(component, 0)
                    change = new_w - old_w
                    
                    print(f"   {component.upper()}: {old_w:.3f} ‚Üí {new_w:.3f} ({change:+.3f})")
                
                metrics = results.get('metrics', {})
                improvement = metrics.get('improvement', 0)
                print(f"\nüìà –ü–æ–¥–æ–±—Ä–µ–Ω–∏–µ –≤ log_loss: {improvement:.1%}")
            else:
                print("üìä –¢–µ–≥–ª–∞—Ç–∞ –Ω–µ —Å–∞ –ø—Ä–æ–º–µ–Ω–µ–Ω–∏ (–Ω–µ–¥–æ—Å—Ç–∞—Ç—ä—á–Ω–æ –ø–æ–¥–æ–±—Ä–µ–Ω–∏–µ)")
        else:
            error = results.get('error', 'Unknown error')
            print(f"‚ùå –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è—Ç–∞ —Å–µ –ø—Ä–æ–≤–∞–ª–∏: {error}")
        
        # –ó–∞–ø–∞–∑–≤–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ
        results_file = "logs/ensemble_optimization_results.json"
        os.makedirs(os.path.dirname(results_file), exist_ok=True)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞ numpy bool –≤ Python bool –∑–∞ JSON serialization
        def convert_for_json(obj):
            if isinstance(obj, np.bool_):
                return bool(obj)
            elif isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, dict):
                return {k: convert_for_json(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_for_json(item) for item in obj]
            return obj
        
        results_json = convert_for_json(results)
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results_json, f, indent=2, ensure_ascii=False)
        
        logger.info(f"üíæ –†–µ–∑—É–ª—Ç–∞—Ç–∏ –∑–∞–ø–∞–∑–µ–Ω–∏ –≤ {results_file}")
        logger.info("‚úÖ Ensemble optimization –∑–∞–≤—ä—Ä—à–µ–Ω")
        
    except Exception as e:
        logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –≤ ensemble optimization: {e}")
        raise


if __name__ == "__main__":
    main()
