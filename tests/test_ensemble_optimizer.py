#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–æ–≤–µ –∑–∞ Dynamic Ensemble Optimizer
"""

import sys
import os
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

import unittest
import tempfile
import shutil
import json
import pandas as pd
import numpy as np
import yaml
from datetime import datetime, timedelta
from unittest.mock import patch, MagicMock

from pipelines.ensemble_optimizer import EnsembleOptimizer, optimize_ensemble_weights


class TestEnsembleOptimizer(unittest.TestCase):
    """–¢–µ—Å—Ç–æ–≤–µ –∑–∞ EnsembleOptimizer –∫–ª–∞—Å–∞"""
    
    def setUp(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–µ–¥–∏ –≤—Å–µ–∫–∏ —Ç–µ—Å—Ç"""
        # –°—ä–∑–¥–∞–≤–∞ –≤—Ä–µ–º–µ–Ω–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
        self.temp_dir = tempfile.mkdtemp()
        
        # –°—ä–∑–¥–∞–≤–∞ —Ç–µ—Å—Ç–æ–≤–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        self.test_config = {
            'ensemble': {
                'current_weights': {
                    'poisson': 0.30,
                    'ml': 0.50,
                    'elo': 0.20
                },
                'optimization': {
                    'enabled': True,
                    'min_improvement': 0.02,
                    'lookback_days': 30,
                    'weight_constraints': {
                        'min_weight': 0.1,
                        'max_weight': 0.8
                    },
                    'cross_validation_folds': 3,
                    'validation_threshold': 0.01
                },
                'backup': {
                    'enabled': True,
                    'max_backups': 5,
                    'backup_dir': os.path.join(self.temp_dir, 'backups/')
                },
                'logging': {
                    'enabled': True,
                    'log_file': os.path.join(self.temp_dir, 'ensemble.log')
                },
                'history': {
                    'optimization_count': 0
                }
            }
        }
        
        # –°—ä–∑–¥–∞–≤–∞ —Ç–µ—Å—Ç–æ–≤ config —Ñ–∞–π–ª
        self.config_path = os.path.join(self.temp_dir, 'ensemble_weights.yaml')
        with open(self.config_path, 'w') as f:
            yaml.dump(self.test_config, f)
        
        # –°—ä–∑–¥–∞–≤–∞ —Ç–µ—Å—Ç–æ–≤–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏ –¥–∞–Ω–Ω–∏
        self.test_data = self._create_test_data()
    
    def tearDown(self):
        """–ü–æ—á–∏—Å—Ç–≤–∞–Ω–µ —Å–ª–µ–¥ –≤—Å–µ–∫–∏ —Ç–µ—Å—Ç"""
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def _create_test_data(self) -> pd.DataFrame:
        """–°—ä–∑–¥–∞–≤–∞ —Ç–µ—Å—Ç–æ–≤–∏ –¥–∞–Ω–Ω–∏ –∑–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è"""
        np.random.seed(42)
        n_samples = 200
        
        # –°–∏–º—É–ª–∏—Ä–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–Ω–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏
        poisson_pred = np.random.beta(2, 2, n_samples)  # Poisson predictions
        ml_pred = np.random.beta(2.5, 2.5, n_samples)  # ML predictions (–ø–æ-–¥–æ–±—Ä–∏)
        elo_pred = np.random.beta(1.5, 1.5, n_samples)  # Elo predictions (–ø–æ-—Å–ª–∞–±–∏)
        
        # –°–∏–º—É–ª–∏—Ä–∞ —Ä–µ–∞–ª–Ω–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏ (–∫–æ—Ä–µ–ª–∏—Ä–∞–Ω–∏ —Å ML)
        actual_result = (ml_pred + np.random.normal(0, 0.1, n_samples) > 0.5).astype(int)
        
        # Timestamps
        timestamps = [
            (datetime.now() - timedelta(days=i)).isoformat()
            for i in range(n_samples-1, -1, -1)
        ]
        
        return pd.DataFrame({
            'timestamp': timestamps,
            'poisson_prediction': poisson_pred,
            'ml_prediction': ml_pred,
            'elo_prediction': elo_pred,
            'actual_result': actual_result
        })
    
    def create_test_optimizer(self):
        """–°—ä–∑–¥–∞–≤–∞ —Ç–µ—Å—Ç–æ–≤ EnsembleOptimizer"""
        return EnsembleOptimizer(self.config_path)
    
    def test_initialization(self):
        """–¢–µ—Å—Ç –∑–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ EnsembleOptimizer"""
        optimizer = self.create_test_optimizer()
        
        self.assertIsNotNone(optimizer.config)
        self.assertIsNotNone(optimizer.logger)
        self.assertTrue(optimizer.opt_config['enabled'])
        self.assertEqual(optimizer.current_weights['poisson'], 0.30)
        self.assertEqual(optimizer.current_weights['ml'], 0.50)
        self.assertEqual(optimizer.current_weights['elo'], 0.20)
    
    def test_load_historical_predictions_empty(self):
        """–¢–µ—Å—Ç –∑–∞ –∑–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏ –¥–∞–Ω–Ω–∏ –ø—Ä–∏ –ª–∏–ø—Å–≤–∞—â —Ñ–∞–π–ª"""
        optimizer = self.create_test_optimizer()
        
        df = optimizer.load_historical_predictions()
        
        self.assertTrue(df.empty)
    
    @patch('pipelines.ensemble_optimizer.os.path.exists')
    def test_load_historical_predictions_with_data(self, mock_exists):
        """–¢–µ—Å—Ç –∑–∞ –∑–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏ –¥–∞–Ω–Ω–∏"""
        optimizer = self.create_test_optimizer()
        
        # –ú–æ–∫–∏—Ä–∞ —á–µ —Ñ–∞–π–ª—ä—Ç —Å—ä—â–µ—Å—Ç–≤—É–≤–∞
        mock_exists.return_value = True
        
        # –°—ä–∑–¥–∞–≤–∞ —Ç–µ—Å—Ç–æ–≤ JSONL —Ñ–∞–π–ª
        history_file = "logs/predictions_history/ou25_predictions.jsonl"
        os.makedirs(os.path.dirname(history_file), exist_ok=True)
        
        with open(history_file, 'w') as f:
            for _, row in self.test_data.iterrows():
                json_line = {
                    'timestamp': row['timestamp'],
                    'poisson_prediction': row['poisson_prediction'],
                    'ml_prediction': row['ml_prediction'],
                    'elo_prediction': row['elo_prediction'],
                    'actual_result': row['actual_result']
                }
                f.write(json.dumps(json_line) + '\n')
        
        try:
            df = optimizer.load_historical_predictions(days=30)
            
            self.assertFalse(df.empty)
            self.assertIn('poisson_prediction', df.columns)
            self.assertIn('ml_prediction', df.columns)
            self.assertIn('elo_prediction', df.columns)
            self.assertIn('actual_result', df.columns)
        finally:
            if os.path.exists(history_file):
                os.remove(history_file)
    
    def test_evaluate_component_performance(self):
        """–¢–µ—Å—Ç –∑–∞ –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏—Ç–µ"""
        optimizer = self.create_test_optimizer()
        
        performance = optimizer.evaluate_component_performance(self.test_data)
        
        self.assertIsInstance(performance, dict)
        
        # –ü—Ä–æ–≤–µ—Ä—è–≤–∞ —á–µ –≤—Å–∏—á–∫–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ —Å–∞ –æ—Ü–µ–Ω–µ–Ω–∏
        expected_components = ['poisson', 'ml', 'elo']
        for component in expected_components:
            self.assertIn(component, performance)
            
            metrics = performance[component]
            self.assertIn('log_loss', metrics)
            self.assertIn('brier_score', metrics)
            self.assertIn('accuracy', metrics)
            self.assertIn('samples', metrics)
            
            # –ü—Ä–æ–≤–µ—Ä—è–≤–∞ –≤–∞–ª–∏–¥–Ω–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏
            self.assertGreater(metrics['log_loss'], 0)
            self.assertGreaterEqual(metrics['brier_score'], 0)
            self.assertLessEqual(metrics['brier_score'], 1)
            self.assertGreaterEqual(metrics['accuracy'], 0)
            self.assertLessEqual(metrics['accuracy'], 1)
    
    def test_ensemble_predictions(self):
        """–¢–µ—Å—Ç –∑–∞ ensemble –ø—Ä–æ–≥–Ω–æ–∑–∏"""
        optimizer = self.create_test_optimizer()
        
        weights = {'poisson': 0.3, 'ml': 0.5, 'elo': 0.2}
        ensemble_pred = optimizer._ensemble_predictions(self.test_data, weights)
        
        self.assertEqual(len(ensemble_pred), len(self.test_data))
        self.assertTrue(np.all(ensemble_pred >= 0))
        self.assertTrue(np.all(ensemble_pred <= 1))
        
        # –ü—Ä–æ–≤–µ—Ä—è–≤–∞ —á–µ ensemble –µ –∫–æ–º–±–∏–Ω–∞—Ü–∏—è –æ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏—Ç–µ
        expected = (
            0.3 * self.test_data['poisson_prediction'].values +
            0.5 * self.test_data['ml_prediction'].values +
            0.2 * self.test_data['elo_prediction'].values
        )
        np.testing.assert_array_almost_equal(ensemble_pred, expected)
    
    def test_optimize_weights_returns_valid_sum(self):
        """–¢–µ—Å—Ç —á–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è—Ç–∞ –≤—Ä—ä—â–∞ —Ç–µ–≥–ª–∞ —Å—ä—Å —Å—É–º–∞ = 1.0"""
        optimizer = self.create_test_optimizer()
        
        new_weights, metrics = optimizer.optimize_weights(self.test_data)
        
        # –ü—Ä–æ–≤–µ—Ä—è–≤–∞ —Å—É–º–∞—Ç–∞ –Ω–∞ —Ç–µ–≥–ª–∞—Ç–∞
        weights_sum = sum(new_weights.values())
        self.assertAlmostEqual(weights_sum, 1.0, places=6)
        
        # –ü—Ä–æ–≤–µ—Ä—è–≤–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è—Ç–∞
        for component, weight in new_weights.items():
            if weight > 0:  # –°–∞–º–æ –∑–∞ –∞–∫—Ç–∏–≤–Ω–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏
                self.assertGreaterEqual(weight, 0.1)
                self.assertLessEqual(weight, 0.8)
        
        # –ü—Ä–æ–≤–µ—Ä—è–≤–∞ –º–µ—Ç—Ä–∏–∫–∏
        self.assertIn('current_log_loss', metrics)
        self.assertIn('new_log_loss', metrics)
        self.assertIn('improvement', metrics)
    
    def test_optimize_weights_empty_data(self):
        """–¢–µ—Å—Ç –∑–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å –ø—Ä–∞–∑–Ω–∏ –¥–∞–Ω–Ω–∏"""
        optimizer = self.create_test_optimizer()
        
        empty_df = pd.DataFrame()
        new_weights, metrics = optimizer.optimize_weights(empty_df)
        
        # –¢—Ä—è–±–≤–∞ –¥–∞ –≤—ä—Ä–Ω–µ —Ç–µ–∫—É—â–∏—Ç–µ —Ç–µ–≥–ª–∞
        self.assertEqual(new_weights, optimizer.current_weights)
        self.assertEqual(metrics, {})
    
    def test_validate_new_weights_insufficient_improvement(self):
        """–¢–µ—Å—Ç –∑–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç—ä—á–Ω–æ –ø–æ–¥–æ–±—Ä–µ–Ω–∏–µ"""
        optimizer = self.create_test_optimizer()
        
        new_weights = {'poisson': 0.31, 'ml': 0.49, 'elo': 0.20}
        metrics = {'improvement': 0.01}  # –ü–æ-–º–∞–ª–∫–æ –æ—Ç 2%
        
        is_valid = optimizer.validate_new_weights(self.test_data, new_weights, metrics)
        
        self.assertFalse(is_valid)
    
    def test_validate_new_weights_sufficient_improvement(self):
        """–¢–µ—Å—Ç –∑–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–∏ –¥–æ—Å—Ç–∞—Ç—ä—á–Ω–æ –ø–æ–¥–æ–±—Ä–µ–Ω–∏–µ"""
        optimizer = self.create_test_optimizer()
        
        new_weights = {'poisson': 0.20, 'ml': 0.60, 'elo': 0.20}
        metrics = {'improvement': 0.05}  # 5% –ø–æ–¥–æ–±—Ä–µ–Ω–∏–µ
        
        is_valid = optimizer.validate_new_weights(self.test_data, new_weights, metrics)
        
        self.assertTrue(is_valid)
    
    def test_validate_new_weights_invalid_sum(self):
        """–¢–µ—Å—Ç –∑–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å –Ω–µ–≤–∞–ª–∏–¥–Ω–∞ —Å—É–º–∞ –Ω–∞ —Ç–µ–≥–ª–∞"""
        optimizer = self.create_test_optimizer()
        
        new_weights = {'poisson': 0.30, 'ml': 0.50, 'elo': 0.30}  # –°—É–º–∞ = 1.1
        metrics = {'improvement': 0.05}
        
        is_valid = optimizer.validate_new_weights(self.test_data, new_weights, metrics)
        
        self.assertFalse(is_valid)
    
    def test_validate_new_weights_constraint_violation(self):
        """–¢–µ—Å—Ç –∑–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å –Ω–∞—Ä—É—à–µ–Ω–∏–µ –Ω–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è—Ç–∞"""
        optimizer = self.create_test_optimizer()
        
        new_weights = {'poisson': 0.05, 'ml': 0.85, 'elo': 0.10}  # poisson < 0.1, ml > 0.8
        metrics = {'improvement': 0.05}
        
        is_valid = optimizer.validate_new_weights(self.test_data, new_weights, metrics)
        
        self.assertFalse(is_valid)
    
    def test_backup_and_update_workflow(self):
        """–¢–µ—Å—Ç –∑–∞ backup –∏ update workflow"""
        optimizer = self.create_test_optimizer()
        
        # –°—ä–∑–¥–∞–≤–∞ backup
        backup_path = optimizer.backup_old_weights()
        
        self.assertTrue(os.path.exists(backup_path))
        self.assertTrue(backup_path.endswith('.yaml'))
        
        # –¢–µ—Å—Ç–≤–∞ update –Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è—Ç–∞
        new_weights = {'poisson': 0.25, 'ml': 0.55, 'elo': 0.20}
        metrics = {'improvement': 0.05, 'new_log_loss': 0.65}
        
        optimizer.update_weights_config(new_weights, metrics, backup_path)
        
        # –ü—Ä–æ–≤–µ—Ä—è–≤–∞ —á–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è—Ç–∞ –µ –æ–±–Ω–æ–≤–µ–Ω–∞
        with open(optimizer.config_path, 'r') as f:
            updated_config = yaml.safe_load(f)
        
        self.assertEqual(
            updated_config['ensemble']['current_weights'],
            new_weights
        )
        self.assertIsNotNone(
            updated_config['ensemble']['history']['last_optimization']
        )
    
    def test_cross_validate_weights(self):
        """–¢–µ—Å—Ç –∑–∞ cross validation –Ω–∞ —Ç–µ–≥–ª–∞"""
        optimizer = self.create_test_optimizer()
        
        # –¢–µ–≥–ª–∞ –∫–æ–∏—Ç–æ —Ç—Ä—è–±–≤–∞ –¥–∞ —Å–∞ –ø–æ-–¥–æ–±—Ä–∏ –æ—Ç —Ç–µ–∫—É—â–∏—Ç–µ
        better_weights = {'poisson': 0.20, 'ml': 0.60, 'elo': 0.20}
        
        cv_result = optimizer._cross_validate_weights(self.test_data, better_weights)
        
        # CV –º–æ–∂–µ –¥–∞ –µ —É—Å–ø–µ—à–Ω–∞ –∏–ª–∏ –Ω–µ—É—Å–ø–µ—à–Ω–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç –æ—Ç –¥–∞–Ω–Ω–∏—Ç–µ
        self.assertIsInstance(cv_result, bool)
    
    def test_cleanup_old_backups(self):
        """–¢–µ—Å—Ç –∑–∞ –ø–æ—á–∏—Å—Ç–≤–∞–Ω–µ –Ω–∞ —Å—Ç–∞—Ä–∏ backup-–∏"""
        optimizer = self.create_test_optimizer()
        
        # –°—ä–∑–¥–∞–≤–∞ –Ω—è–∫–æ–ª–∫–æ backup —Ñ–∞–π–ª–∞
        backup_dir = Path(optimizer.backup_dir)
        backup_dir.mkdir(parents=True, exist_ok=True)
        
        for i in range(7):  # –ü–æ–≤–µ—á–µ –æ—Ç max_backups (5)
            backup_file = backup_dir / f"ensemble_weights_202301{i:02d}_120000.yaml"
            backup_file.write_text("test content")
        
        # –ò–∑–≤–∏–∫–≤–∞ cleanup
        optimizer._cleanup_old_backups()
        
        # –ü—Ä–æ–≤–µ—Ä—è–≤–∞ —á–µ —Å–∞ –æ—Å—Ç–∞–Ω–∞–ª–∏ —Å–∞–º–æ 5 —Ñ–∞–π–ª–∞
        remaining_files = list(backup_dir.glob("ensemble_weights_*.yaml"))
        self.assertLessEqual(len(remaining_files), 5)


class TestEnsembleOptimizerIntegration(unittest.TestCase):
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω–∏ —Ç–µ—Å—Ç–æ–≤–µ –∑–∞ EnsembleOptimizer"""
    
    def setUp(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–µ–¥–∏ –≤—Å–µ–∫–∏ —Ç–µ—Å—Ç"""
        self.temp_dir = tempfile.mkdtemp()
    
    def tearDown(self):
        """–ü–æ—á–∏—Å—Ç–≤–∞–Ω–µ —Å–ª–µ–¥ –≤—Å–µ–∫–∏ —Ç–µ—Å—Ç"""
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_optimize_ensemble_weights_function(self):
        """–¢–µ—Å—Ç –∑–∞ convenience —Ñ—É–Ω–∫—Ü–∏—è—Ç–∞ optimize_ensemble_weights"""
        # –°—ä–∑–¥–∞–≤–∞ –≤—Ä–µ–º–µ–Ω–µ–Ω config
        config_path = os.path.join(self.temp_dir, 'ensemble_weights.yaml')
        test_config = {
            'ensemble': {
                'current_weights': {'poisson': 0.30, 'ml': 0.50, 'elo': 0.20},
                'optimization': {'enabled': False}  # –ò–∑–∫–ª—é—á–µ–Ω–∞ –∑–∞ —Ç–µ—Å—Ç–∞
            }
        }
        
        with open(config_path, 'w') as f:
            yaml.dump(test_config, f)
        
        with patch('pipelines.ensemble_optimizer.EnsembleOptimizer') as mock_optimizer_class:
            mock_optimizer = MagicMock()
            mock_optimizer.optimize_ensemble_weights.return_value = {'enabled': False}
            mock_optimizer_class.return_value = mock_optimizer
            
            result = optimize_ensemble_weights()
            
            self.assertIsInstance(result, dict)
            mock_optimizer_class.assert_called_once()
            mock_optimizer.optimize_ensemble_weights.assert_called_once()
    
    def test_integration_with_performance_monitor(self):
        """–¢–µ—Å—Ç –∑–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å performance monitor"""
        # –°–∏–º—É–ª–∏—Ä–∞ –∏–∑–≤–∏–∫–≤–∞–Ω–µ –æ—Ç performance monitor
        with patch('pipelines.ensemble_optimizer.EnsembleOptimizer') as mock_optimizer_class:
            mock_optimizer = MagicMock()
            mock_optimizer.optimize_ensemble_weights.return_value = {
                'enabled': True,
                'success': True,
                'weights_updated': True,
                'metrics': {'improvement': 0.05}
            }
            mock_optimizer_class.return_value = mock_optimizer
            
            # –ò–∑–≤–∏–∫–≤–∞ optimize_ensemble_weights (–∫–∞–∫—Ç–æ –≤ performance_monitor.py)
            try:
                from pipelines.ensemble_optimizer import optimize_ensemble_weights
                result = optimize_ensemble_weights()
                
                # –ü—Ä–æ–≤–µ—Ä—è–≤–∞ —á–µ –Ω—è–º–∞ –≥—Ä–µ—à–∫–∏
                self.assertIsInstance(result, dict)
                self.assertTrue(result.get('enabled', False))
                
            except Exception as e:
                self.fail(f"Integration test failed with error: {e}")
    
    def test_config_loading_fallback(self):
        """–¢–µ—Å—Ç –∑–∞ fallback –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–∏ –ª–∏–ø—Å–≤–∞—â —Ñ–∞–π–ª"""
        optimizer = EnsembleOptimizer('nonexistent_config.yaml')
        
        # –¢—Ä—è–±–≤–∞ –¥–∞ –∏–∑–ø–æ–ª–∑–≤–∞ fallback –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        self.assertIsNotNone(optimizer.config)
        self.assertIn('ensemble', optimizer.config)
        self.assertIn('current_weights', optimizer.config['ensemble'])


def run_tests():
    """–°—Ç–∞—Ä—Ç–∏—Ä–∞ –≤—Å–∏—á–∫–∏ —Ç–µ—Å—Ç–æ–≤–µ"""
    # –°—ä–∑–¥–∞–≤–∞ test suite
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()
    
    # –î–æ–±–∞–≤—è —Ç–µ—Å—Ç–æ–≤–µ—Ç–µ
    suite.addTests(loader.loadTestsFromTestCase(TestEnsembleOptimizer))
    suite.addTests(loader.loadTestsFromTestCase(TestEnsembleOptimizerIntegration))
    
    # –°—Ç–∞—Ä—Ç–∏—Ä–∞ —Ç–µ—Å—Ç–æ–≤–µ—Ç–µ
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    return result.wasSuccessful()


if __name__ == '__main__':
    print("üß™ –°–¢–ê–†–¢–ò–†–ê–ù–ï –ù–ê ENSEMBLE OPTIMIZER –¢–ï–°–¢–û–í–ï")
    print("=" * 70)
    
    success = run_tests()
    
    if success:
        print("\n‚úÖ –í—Å–∏—á–∫–∏ —Ç–µ—Å—Ç–æ–≤–µ –º–∏–Ω–∞—Ö–∞ —É—Å–ø–µ—à–Ω–æ!")
    else:
        print("\n‚ùå –ù—è–∫–æ–∏ —Ç–µ—Å—Ç–æ–≤–µ —Å–µ –ø—Ä–æ–≤–∞–ª–∏—Ö–∞!")
        sys.exit(1)
