#!/usr/bin/env python3
"""
A/B —Ç–µ—Å—Ç–≤–∞–Ω–µ –Ω–∞ per-league vs global OU2.5 –º–æ–¥–µ–ª–∏
"""

import sys
import os
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

import pandas as pd
import numpy as np
import requests
import json
import time
from datetime import datetime
from typing import Dict, List, Tuple
import matplotlib.pyplot as plt
import seaborn as sns

from core.league_utils import LEAGUE_ID_TO_SLUG, get_league_display_name
from core.utils import setup_logging


class PerLeagueABTester:
    """
    A/B —Ç–µ—Å—Ç–≤–∞–Ω–µ –Ω–∞ per-league vs global –º–æ–¥–µ–ª–∏
    """
    
    def __init__(self, api_url: str = "http://localhost:3000"):
        self.api_url = api_url
        self.logger = setup_logging()
        self.results = []
        
    def test_league_models(self, test_matches: pd.DataFrame, max_tests: int = 50) -> Dict:
        """
        –¢–µ—Å—Ç–≤–∞ per-league –º–æ–¥–µ–ª–∏ —Å—Ä–µ—â—É –≥–ª–æ–±–∞–ª–µ–Ω –º–æ–¥–µ–ª
        
        Args:
            test_matches: Test –¥–∞–Ω–Ω–∏
            max_tests: –ú–∞–∫—Å–∏–º–∞–ª–µ–Ω –±—Ä–æ–π —Ç–µ—Å—Ç–æ–≤–µ –Ω–∞ –ª–∏–≥–∞
        
        Returns:
            –†–µ–∑—É–ª—Ç–∞—Ç–∏ –æ—Ç A/B —Ç–µ—Å—Ç–∞
        """
        self.logger.info("üß™ –°—Ç–∞—Ä—Ç–∏—Ä–∞–Ω–µ –Ω–∞ A/B —Ç–µ—Å—Ç–≤–∞–Ω–µ...")
        
        results_by_league = {}
        
        # –ì—Ä—É–ø–∏—Ä–∞ –ø–æ –ª–∏–≥–∏
        for league_id, league_data in test_matches.groupby('league_id'):
            if league_id not in LEAGUE_ID_TO_SLUG:
                continue
                
            league_slug = LEAGUE_ID_TO_SLUG[league_id]
            league_name = get_league_display_name(league_slug)
            
            self.logger.info(f"üèÜ –¢–µ—Å—Ç–≤–∞–Ω–µ –Ω–∞ {league_name} ({len(league_data)} –º–∞—á–∞)")
            
            # –û–≥—Ä–∞–Ω–∏—á–∞–≤–∞ –±—Ä–æ—è —Ç–µ—Å—Ç–æ–≤–µ
            test_sample = league_data.sample(min(max_tests, len(league_data)), random_state=42)
            
            league_results = []
            
            for idx, match in test_sample.iterrows():
                try:
                    # –°–∏–º—É–ª–∏—Ä–∞ –º–∞—á —Å —Ñ–∏–∫—Ç–∏–≤–Ω–∏ –æ—Ç–±–æ—Ä–∏
                    home_team = f"Team_{match['home_team_id']}"
                    away_team = f"Team_{match['away_team_id']}"
                    
                    # API –∑–∞—è–≤–∫–∞
                    response = requests.post(
                        f"{self.api_url}/predict",
                        json={
                            "home_team": home_team,
                            "away_team": away_team,
                            "league": league_name
                        },
                        timeout=10
                    )
                    
                    if response.status_code == 200:
                        prediction = response.json()
                        
                        # –ò–∑–≤–ª–∏—á–∞ OU2.5 –¥–∞–Ω–Ω–∏
                        ou25_pred = prediction.get('prediction_ou25', {})
                        model_source = prediction.get('model_sources', {}).get('ou25', 'unknown')
                        
                        # –†–µ–∞–ª–µ–Ω —Ä–µ–∑—É–ª—Ç–∞—Ç
                        actual_over = match['over_25']
                        predicted_prob = ou25_pred.get('prob_over', 0.5)
                        predicted_outcome = 1 if predicted_prob > 0.5 else 0
                        
                        # –ú–µ—Ç—Ä–∏–∫–∏
                        correct = (predicted_outcome == actual_over)
                        log_loss = -(actual_over * np.log(max(predicted_prob, 1e-15)) + 
                                   (1 - actual_over) * np.log(max(1 - predicted_prob, 1e-15)))
                        brier_score = (predicted_prob - actual_over) ** 2
                        
                        league_results.append({
                            'match_id': match.get('match_id', idx),
                            'home_team_id': match['home_team_id'],
                            'away_team_id': match['away_team_id'],
                            'actual_over': actual_over,
                            'predicted_prob': predicted_prob,
                            'predicted_outcome': predicted_outcome,
                            'correct': correct,
                            'log_loss': log_loss,
                            'brier_score': brier_score,
                            'model_source': model_source,
                            'league_id': league_id,
                            'league_slug': league_slug,
                            'league_name': league_name
                        })
                        
                    else:
                        self.logger.warning(f"API –≥—Ä–µ—à–∫–∞ –∑–∞ –º–∞—á {idx}: {response.status_code}")
                        
                except Exception as e:
                    self.logger.warning(f"–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–≤–∞–Ω–µ –Ω–∞ –º–∞—á {idx}: {e}")
                    
                # Rate limiting
                time.sleep(0.1)
            
            if league_results:
                results_by_league[league_slug] = league_results
                self.logger.info(f"‚úÖ {league_name}: {len(league_results)} —É—Å–ø–µ—à–Ω–∏ —Ç–µ—Å—Ç–∞")
            else:
                self.logger.warning(f"‚ùå {league_name}: –ù—è–º–∞ —É—Å–ø–µ—à–Ω–∏ —Ç–µ—Å—Ç–æ–≤–µ")
        
        return results_by_league
    
    def analyze_results(self, results_by_league: Dict) -> Dict:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ –æ—Ç A/B —Ç–µ—Å—Ç–∞
        
        Args:
            results_by_league: –†–µ–∑—É–ª—Ç–∞—Ç–∏ –ø–æ –ª–∏–≥–∏
        
        Returns:
            –ê–Ω–∞–ª–∏–∑ –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ
        """
        self.logger.info("üìä –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–µ –Ω–∞ A/B —Ç–µ—Å—Ç —Ä–µ–∑—É–ª—Ç–∞—Ç–∏...")
        
        analysis = {
            'league_performance': {},
            'model_comparison': {
                'league_ou25': {'accuracy': [], 'log_loss': [], 'brier_score': [], 'count': 0},
                'global_ou25': {'accuracy': [], 'log_loss': [], 'brier_score': [], 'count': 0}
            },
            'summary': {}
        }
        
        all_results = []
        
        for league_slug, league_results in results_by_league.items():
            league_name = get_league_display_name(league_slug)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞ –≤ DataFrame
            df = pd.DataFrame(league_results)
            all_results.extend(league_results)
            
            # –ê–Ω–∞–ª–∏–∑ –ø–æ –º–æ–¥–µ–ª source
            league_model_results = df[df['model_source'] == 'league_ou25']
            global_model_results = df[df['model_source'] == 'global_ou25']
            
            league_perf = {
                'total_tests': len(df),
                'league_model_tests': len(league_model_results),
                'global_model_tests': len(global_model_results),
                'overall_accuracy': df['correct'].mean(),
                'overall_log_loss': df['log_loss'].mean(),
                'overall_brier_score': df['brier_score'].mean()
            }
            
            if len(league_model_results) > 0:
                league_perf['league_model_accuracy'] = league_model_results['correct'].mean()
                league_perf['league_model_log_loss'] = league_model_results['log_loss'].mean()
                league_perf['league_model_brier_score'] = league_model_results['brier_score'].mean()
                
                # –î–æ–±–∞–≤—è –∫—ä–º –æ–±—â–∏—è –∞–Ω–∞–ª–∏–∑
                analysis['model_comparison']['league_ou25']['accuracy'].extend(league_model_results['correct'].tolist())
                analysis['model_comparison']['league_ou25']['log_loss'].extend(league_model_results['log_loss'].tolist())
                analysis['model_comparison']['league_ou25']['brier_score'].extend(league_model_results['brier_score'].tolist())
                analysis['model_comparison']['league_ou25']['count'] += len(league_model_results)
            
            if len(global_model_results) > 0:
                league_perf['global_model_accuracy'] = global_model_results['correct'].mean()
                league_perf['global_model_log_loss'] = global_model_results['log_loss'].mean()
                league_perf['global_model_brier_score'] = global_model_results['brier_score'].mean()
                
                # –î–æ–±–∞–≤—è –∫—ä–º –æ–±—â–∏—è –∞–Ω–∞–ª–∏–∑
                analysis['model_comparison']['global_ou25']['accuracy'].extend(global_model_results['correct'].tolist())
                analysis['model_comparison']['global_ou25']['log_loss'].extend(global_model_results['log_loss'].tolist())
                analysis['model_comparison']['global_ou25']['brier_score'].extend(global_model_results['brier_score'].tolist())
                analysis['model_comparison']['global_ou25']['count'] += len(global_model_results)
            
            analysis['league_performance'][league_slug] = league_perf
        
        # –û–±—â summary
        if all_results:
            all_df = pd.DataFrame(all_results)
            
            analysis['summary'] = {
                'total_tests': len(all_df),
                'leagues_tested': len(results_by_league),
                'league_model_usage': (all_df['model_source'] == 'league_ou25').sum(),
                'global_model_usage': (all_df['model_source'] == 'global_ou25').sum(),
                'overall_accuracy': all_df['correct'].mean(),
                'overall_log_loss': all_df['log_loss'].mean(),
                'overall_brier_score': all_df['brier_score'].mean()
            }
            
            # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ–∂–¥—É –º–æ–¥–µ–ª–∏—Ç–µ
            for model_type in ['league_ou25', 'global_ou25']:
                model_data = analysis['model_comparison'][model_type]
                if model_data['count'] > 0:
                    model_data['avg_accuracy'] = np.mean(model_data['accuracy'])
                    model_data['avg_log_loss'] = np.mean(model_data['log_loss'])
                    model_data['avg_brier_score'] = np.mean(model_data['brier_score'])
        
        return analysis
    
    def generate_report(self, analysis: Dict, output_file: str = None) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä–∞ –æ—Ç—á–µ—Ç –æ—Ç A/B —Ç–µ—Å—Ç–∞
        
        Args:
            analysis: –ê–Ω–∞–ª–∏–∑ –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ
            output_file: –§–∞–π–ª –∑–∞ –∑–∞–ø–∞–∑–≤–∞–Ω–µ
        
        Returns:
            –¢–µ–∫—Å—Ç–æ–≤ –æ—Ç—á–µ—Ç
        """
        report_lines = [
            "üß™ A/B –¢–ï–°–¢: PER-LEAGUE vs GLOBAL OU2.5 –ú–û–î–ï–õ–ò",
            "=" * 60,
            f"–î–∞—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            ""
        ]
        
        # Summary
        summary = analysis.get('summary', {})
        if summary:
            report_lines.extend([
                "üìä –û–ë–© –ü–†–ï–ì–õ–ï–î:",
                f"   –û–±—â–æ —Ç–µ—Å—Ç–æ–≤–µ: {summary['total_tests']}",
                f"   –¢–µ—Å—Ç–≤–∞–Ω–∏ –ª–∏–≥–∏: {summary['leagues_tested']}",
                f"   League –º–æ–¥–µ–ª –∏–∑–ø–æ–ª–∑–≤–∞–Ω: {summary['league_model_usage']} –ø—ä—Ç–∏",
                f"   Global –º–æ–¥–µ–ª –∏–∑–ø–æ–ª–∑–≤–∞–Ω: {summary['global_model_usage']} –ø—ä—Ç–∏",
                f"   –û–±—â accuracy: {summary['overall_accuracy']:.3f}",
                f"   –û–±—â log loss: {summary['overall_log_loss']:.3f}",
                f"   –û–±—â Brier score: {summary['overall_brier_score']:.3f}",
                ""
            ])
        
        # Model comparison
        model_comp = analysis.get('model_comparison', {})
        if model_comp:
            report_lines.extend([
                "‚öñÔ∏è –°–†–ê–í–ù–ï–ù–ò–ï –ù–ê –ú–û–î–ï–õ–ò–¢–ï:",
                ""
            ])
            
            for model_type, data in model_comp.items():
                if data['count'] > 0:
                    model_name = "League-specific" if model_type == 'league_ou25' else "Global"
                    report_lines.extend([
                        f"üîπ {model_name} –º–æ–¥–µ–ª ({data['count']} —Ç–µ—Å—Ç–∞):",
                        f"   Accuracy: {data['avg_accuracy']:.3f}",
                        f"   Log Loss: {data['avg_log_loss']:.3f}",
                        f"   Brier Score: {data['avg_brier_score']:.3f}",
                        ""
                    ])
            
            # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
            if (model_comp['league_ou25']['count'] > 0 and 
                model_comp['global_ou25']['count'] > 0):
                
                acc_diff = model_comp['league_ou25']['avg_accuracy'] - model_comp['global_ou25']['avg_accuracy']
                ll_diff = model_comp['league_ou25']['avg_log_loss'] - model_comp['global_ou25']['avg_log_loss']
                bs_diff = model_comp['league_ou25']['avg_brier_score'] - model_comp['global_ou25']['avg_brier_score']
                
                report_lines.extend([
                    "üéØ –†–ê–ó–õ–ò–ö–ê (League - Global):",
                    f"   Accuracy: {acc_diff:+.3f} ({'–ø–æ–¥–æ–±—Ä–µ–Ω–∏–µ' if acc_diff > 0 else '–≤–ª–æ—à–µ–Ω–∏–µ'})",
                    f"   Log Loss: {ll_diff:+.3f} ({'–≤–ª–æ—à–µ–Ω–∏–µ' if ll_diff > 0 else '–ø–æ–¥–æ–±—Ä–µ–Ω–∏–µ'})",
                    f"   Brier Score: {bs_diff:+.3f} ({'–≤–ª–æ—à–µ–Ω–∏–µ' if bs_diff > 0 else '–ø–æ–¥–æ–±—Ä–µ–Ω–∏–µ'})",
                    ""
                ])
        
        # League performance
        league_perf = analysis.get('league_performance', {})
        if league_perf:
            report_lines.extend([
                "üèÜ PERFORMANCE –ü–û –õ–ò–ì–ò:",
                ""
            ])
            
            for league_slug, perf in league_perf.items():
                league_name = get_league_display_name(league_slug)
                report_lines.extend([
                    f"üî∏ {league_name}:",
                    f"   –û–±—â–æ —Ç–µ—Å—Ç–æ–≤–µ: {perf['total_tests']}",
                    f"   League –º–æ–¥–µ–ª: {perf['league_model_tests']} —Ç–µ—Å—Ç–∞",
                    f"   Global –º–æ–¥–µ–ª: {perf['global_model_tests']} —Ç–µ—Å—Ç–∞",
                    f"   –û–±—â accuracy: {perf['overall_accuracy']:.3f}",
                    f"   –û–±—â log loss: {perf['overall_log_loss']:.3f}",
                    f"   –û–±—â Brier score: {perf['overall_brier_score']:.3f}",
                    ""
                ])
        
        report = "\n".join(report_lines)
        
        if output_file:
            os.makedirs(os.path.dirname(output_file), exist_ok=True)
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(report)
            self.logger.info(f"üìÑ –û—Ç—á–µ—Ç –∑–∞–ø–∞–∑–µ–Ω –≤ {output_file}")
        
        return report


def main():
    """–ì–ª–∞–≤–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è –∑–∞ A/B —Ç–µ—Å—Ç–≤–∞–Ω–µ"""
    logger = setup_logging()
    
    logger.info("üß™ –°–¢–ê–†–¢–ò–†–ê–ù–ï –ù–ê A/B –¢–ï–°–¢–í–ê–ù–ï")
    logger.info("=" * 50)
    
    try:
        # –ó–∞—Ä–µ–∂–¥–∞ test –¥–∞–Ω–Ω–∏
        logger.info("üìÇ –ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ test –¥–∞–Ω–Ω–∏...")
        test_df = pd.read_parquet("data/processed/test_poisson_predictions.parquet")
        
        # –î–æ–±–∞–≤—è league_slug
        test_df['league_slug'] = test_df['league_id'].map(LEAGUE_ID_TO_SLUG)
        
        # –§–∏–ª—Ç—Ä–∏—Ä–∞ —Å–∞–º–æ –ª–∏–≥–∏—Ç–µ —Å —Ç—Ä–µ–Ω–∏—Ä–∞–Ω–∏ –º–æ–¥–µ–ª–∏
        trained_leagues = list(LEAGUE_ID_TO_SLUG.keys())
        test_df_filtered = test_df[test_df['league_id'].isin(trained_leagues)]
        
        logger.info(f"üìä Test –¥–∞–Ω–Ω–∏: {len(test_df_filtered)} –º–∞—á–∞ –æ—Ç {len(trained_leagues)} –ª–∏–≥–∏")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–∞ A/B tester
        tester = PerLeagueABTester()
        
        # –°—Ç–∞—Ä—Ç–∏—Ä–∞ —Ç–µ—Å—Ç–≤–∞–Ω–µ—Ç–æ
        results = tester.test_league_models(test_df_filtered, max_tests=20)  # 20 —Ç–µ—Å—Ç–∞ –Ω–∞ –ª–∏–≥–∞
        
        if results:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ
            analysis = tester.analyze_results(results)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä–∞ –æ—Ç—á–µ—Ç
            report = tester.generate_report(
                analysis, 
                output_file="reports/ab_test_per_league_results.txt"
            )
            
            print(report)
            
            # –ó–∞–ø–∞–∑–≤–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ
            results_file = "reports/ab_test_per_league_data.json"
            os.makedirs(os.path.dirname(results_file), exist_ok=True)
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'timestamp': datetime.now().isoformat(),
                    'results_by_league': results,
                    'analysis': analysis
                }, f, indent=2, ensure_ascii=False)
            
            logger.info(f"üíæ –î–∞–Ω–Ω–∏ –∑–∞–ø–∞–∑–µ–Ω–∏ –≤ {results_file}")
            
        else:
            logger.error("‚ùå –ù—è–º–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏ –æ—Ç A/B —Ç–µ—Å—Ç–∞")
    
    except Exception as e:
        logger.error(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ A/B —Ç–µ—Å—Ç–≤–∞–Ω–µ: {e}")
        raise


if __name__ == "__main__":
    main()
