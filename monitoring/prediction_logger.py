"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –ª–æ–≥–≤–∞–Ω–µ –Ω–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏ –∑–∞ –∫–∞–ª–∏–±—Ä–∞—Ü–∏–æ–Ω–µ–Ω –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
import json
from typing import Dict, Any, Optional
import logging
from pathlib import Path


class PredictionLogger:
    """
    –ö–ª–∞—Å –∑–∞ –ª–æ–≥–≤–∞–Ω–µ –Ω–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏ –∏ —Ä–µ–∞–ª–Ω–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏
    """
    
    def __init__(self, 
                 history_file: str = "logs/predictions_history.parquet",
                 results_file: str = "logs/match_results.parquet"):
        self.history_file = history_file
        self.results_file = results_file
        
        # –°—ä–∑–¥–∞–≤–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        history_dir = os.path.dirname(history_file)
        if history_dir:
            os.makedirs(history_dir, exist_ok=True)
        
        results_dir = os.path.dirname(results_file)
        if results_dir:
            os.makedirs(results_dir, exist_ok=True)
        
        # Setup logging
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
    
    def log_prediction(self, 
                      home_team: str,
                      away_team: str,
                      league: str,
                      prediction_data: Dict[str, Any],
                      match_date: Optional[str] = None) -> str:
        """
        –õ–æ–≥–≤–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞ –∑–∞ –º–∞—á
        
        Args:
            home_team: –ò–º–µ –Ω–∞ –¥–æ–º–∞–∫–∏–Ω–∞
            away_team: –ò–º–µ –Ω–∞ –≥–æ—Å—Ç–∏—Ç–µ
            league: –õ–∏–≥–∞
            prediction_data: –ü—ä–ª–Ω–∏ –¥–∞–Ω–Ω–∏ –æ—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞—Ç–∞
            match_date: –î–∞—Ç–∞ –Ω–∞ –º–∞—á–∞ (–∞–∫–æ –µ —Ä–∞–∑–ª–∏—á–Ω–∞ –æ—Ç –¥–Ω–µ—Å)
        
        Returns:
            Unique ID –Ω–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞—Ç–∞
        """
        # –ì–µ–Ω–µ—Ä–∏—Ä–∞ unique ID
        prediction_id = f"{home_team}_{away_team}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # –ü–æ–¥–≥–æ—Ç–≤—è –¥–∞–Ω–Ω–∏—Ç–µ –∑–∞ –ª–æ–≥–≤–∞–Ω–µ
        log_entry = {
            'prediction_id': prediction_id,
            'prediction_date': datetime.now().isoformat(),
            'match_date': match_date or datetime.now().strftime('%Y-%m-%d'),
            'home_team': home_team,
            'away_team': away_team,
            'league': league,
            
            # 1X2 Predictions
            'pred_1x2_probs': [
                prediction_data['prediction_1x2']['prob_home_win'],
                prediction_data['prediction_1x2']['prob_draw'],
                prediction_data['prediction_1x2']['prob_away_win']
            ],
            'pred_1x2_outcome': prediction_data['prediction_1x2']['predicted_outcome'],
            'pred_1x2_confidence': prediction_data['prediction_1x2']['confidence'],
            
            # OU2.5 Predictions
            'pred_ou25_prob': prediction_data['prediction_ou25']['prob_over'],
            'pred_ou25_outcome': prediction_data['prediction_ou25']['predicted_outcome'],
            'pred_ou25_confidence': prediction_data['prediction_ou25']['confidence'],
            
            # BTTS Predictions
            'pred_btts_prob': prediction_data['prediction_btts']['prob_yes'],
            'pred_btts_outcome': prediction_data['prediction_btts']['predicted_outcome'],
            'pred_btts_confidence': prediction_data['prediction_btts']['confidence'],
            
            # FII Score
            'fii_score': prediction_data['fii']['score'],
            'fii_confidence_level': prediction_data['fii']['confidence_level'],
            
            # Poisson Analysis (–∞–∫–æ –µ –Ω–∞–ª–∏—á–Ω–æ)
            'poisson_lambda_home': prediction_data.get('poisson_analysis', {}).get('lambda_home'),
            'poisson_lambda_away': prediction_data.get('poisson_analysis', {}).get('lambda_away'),
            'poisson_expected_goals': prediction_data.get('poisson_analysis', {}).get('expected_goals'),
            
            # Actual results (—â–µ —Å–µ –ø–æ–ø—ä–ª–Ω—è—Ç –ø–æ-–∫—ä—Å–Ω–æ)
            'actual_home_score': None,
            'actual_away_score': None,
            'result_updated_date': None,
            
            # Metadata (flatten –¥–ª—è Parquet compatibility)
            'model_version_poisson': prediction_data.get('model_versions', {}).get('poisson', 'v1'),
            'model_version_1x2': prediction_data.get('model_versions', {}).get('1x2', 'v1'),
            'model_version_ou25': prediction_data.get('model_versions', {}).get('ou25', 'v1'),
            'model_version_btts': prediction_data.get('model_versions', {}).get('btts', 'v1'),
            'model_version_ensemble': prediction_data.get('model_versions', {}).get('ensemble', 'v1'),
            'api_version': prediction_data.get('api_version', 'v1')
        }
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞ –≤ DataFrame
        df_new = pd.DataFrame([log_entry])
        
        # –î–æ–±–∞–≤—è –∫—ä–º –∏—Å—Ç–æ—Ä–∏—è—Ç–∞
        if os.path.exists(self.history_file):
            try:
                df_existing = pd.read_parquet(self.history_file)
                df_combined = pd.concat([df_existing, df_new], ignore_index=True)
            except Exception as e:
                self.logger.warning(f"Could not read existing history: {e}")
                df_combined = df_new
        else:
            df_combined = df_new
        
        # –ó–∞–ø–∞–∑–≤–∞
        try:
            df_combined.to_parquet(self.history_file, index=False)
            self.logger.info(f"Logged prediction {prediction_id}")
        except Exception as e:
            self.logger.error(f"Failed to save prediction log: {e}")
        
        return prediction_id
    
    def update_match_result(self, 
                           home_team: str,
                           away_team: str,
                           home_score: int,
                           away_score: int,
                           match_date: str) -> bool:
        """
        –û–±–Ω–æ–≤—è–≤–∞ —Ä–µ–∞–ª–Ω–∏—è —Ä–µ–∑—É–ª—Ç–∞—Ç –∑–∞ –º–∞—á
        
        Args:
            home_team: –ò–º–µ –Ω–∞ –¥–æ–º–∞–∫–∏–Ω–∞
            away_team: –ò–º–µ –Ω–∞ –≥–æ—Å—Ç–∏—Ç–µ
            home_score: –ì–æ–ª–æ–≤–µ –Ω–∞ –¥–æ–º–∞–∫–∏–Ω–∞
            away_score: –ì–æ–ª–æ–≤–µ –Ω–∞ –≥–æ—Å—Ç–∏—Ç–µ
            match_date: –î–∞—Ç–∞ –Ω–∞ –º–∞—á–∞
        
        Returns:
            True –∞–∫–æ –æ–±–Ω–æ–≤—è–≤–∞–Ω–µ—Ç–æ –µ —É—Å–ø–µ—à–Ω–æ
        """
        if not os.path.exists(self.history_file):
            self.logger.warning("No prediction history found")
            return False
        
        try:
            df = pd.read_parquet(self.history_file)
            
            # –ù–∞–º–∏—Ä–∞ —Å—ä–æ—Ç–≤–µ—Ç—Å—Ç–≤–∞—â–∏—Ç–µ –ø—Ä–æ–≥–Ω–æ–∑–∏
            mask = (
                (df['home_team'] == home_team) & 
                (df['away_team'] == away_team) & 
                (df['match_date'] == match_date) &
                (df['actual_home_score'].isna())  # –°–∞–º–æ –Ω–µ–æ–±–Ω–æ–≤–µ–Ω–∏
            )
            
            if mask.sum() == 0:
                self.logger.warning(f"No matching predictions found for {home_team} vs {away_team} on {match_date}")
                return False
            
            # –û–±–Ω–æ–≤—è–≤–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ
            df.loc[mask, 'actual_home_score'] = home_score
            df.loc[mask, 'actual_away_score'] = away_score
            df.loc[mask, 'result_updated_date'] = datetime.now().isoformat()
            
            # –ó–∞–ø–∞–∑–≤–∞
            df.to_parquet(self.history_file, index=False)
            
            updated_count = mask.sum()
            self.logger.info(f"Updated {updated_count} predictions for {home_team} vs {away_team}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to update match result: {e}")
            return False
    
    def bulk_update_results(self, results_df: pd.DataFrame) -> int:
        """
        Bulk –æ–±–Ω–æ–≤—è–≤–∞–Ω–µ –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏ –æ—Ç DataFrame
        
        Args:
            results_df: DataFrame —Å –∫–æ–ª–æ–Ω–∏: home_team, away_team, match_date, home_score, away_score
        
        Returns:
            –ë—Ä–æ–π –æ–±–Ω–æ–≤–µ–Ω–∏ –∑–∞–ø–∏—Å–∏
        """
        updated_count = 0
        
        for _, row in results_df.iterrows():
            success = self.update_match_result(
                row['home_team'],
                row['away_team'],
                row['home_score'],
                row['away_score'],
                row['match_date']
            )
            if success:
                updated_count += 1
        
        return updated_count
    
    def get_pending_matches(self, days_back: int = 7) -> pd.DataFrame:
        """
        –ü–æ–ª—É—á–∞–≤–∞ –º–∞—á–æ–≤–µ –±–µ–∑ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏ –æ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏—Ç–µ –¥–Ω–∏
        
        Args:
            days_back: –ë—Ä–æ–π –¥–Ω–∏ –Ω–∞–∑–∞–¥ –∑–∞ —Ç—ä—Ä—Å–µ–Ω–µ
        
        Returns:
            DataFrame —Å –º–∞—á–æ–≤–µ –±–µ–∑ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏
        """
        if not os.path.exists(self.history_file):
            return pd.DataFrame()
        
        try:
            df = pd.read_parquet(self.history_file)
            
            # –§–∏–ª—Ç—Ä–∏—Ä–∞ –ø–æ –¥–∞—Ç–∞
            cutoff_date = datetime.now() - timedelta(days=days_back)
            df['match_date'] = pd.to_datetime(df['match_date'])
            df_recent = df[df['match_date'] >= cutoff_date].copy()
            
            # –ù–∞–º–∏—Ä–∞ –º–∞—á–æ–≤–µ –±–µ–∑ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏
            pending = df_recent[df_recent['actual_home_score'].isna()].copy()
            
            return pending[['prediction_id', 'home_team', 'away_team', 'match_date', 'league']]
            
        except Exception as e:
            self.logger.error(f"Failed to get pending matches: {e}")
            return pd.DataFrame()
    
    def cleanup_old_predictions(self, days_to_keep: int = 365):
        """
        –ò–∑—á–∏—Å—Ç–≤–∞ —Å—Ç–∞—Ä–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏ –∑–∞ –¥–∞ –Ω–µ —Å–µ –Ω–∞—Ç—Ä—É–ø–≤–∞—Ç —Ç–≤—ä—Ä–¥–µ –º–Ω–æ–≥–æ –¥–∞–Ω–Ω–∏
        
        Args:
            days_to_keep: –ë—Ä–æ–π –¥–Ω–∏ –∑–∞ –∑–∞–ø–∞–∑–≤–∞–Ω–µ
        """
        if not os.path.exists(self.history_file):
            return
        
        try:
            df = pd.read_parquet(self.history_file)
            
            # –ò–∑—á–∏—Å–ª—è–≤–∞ cutoff –¥–∞—Ç–∞
            cutoff_date = datetime.now() - timedelta(days=days_to_keep)
            df['prediction_date'] = pd.to_datetime(df['prediction_date'])
            
            # –ó–∞–ø–∞–∑–≤–∞ —Å–∞–º–æ —Å–∫–æ—Ä–æ—à–Ω–∏—Ç–µ
            df_recent = df[df['prediction_date'] >= cutoff_date].copy()
            
            # –ó–∞–ø–∞–∑–≤–∞
            df_recent.to_parquet(self.history_file, index=False)
            
            removed_count = len(df) - len(df_recent)
            self.logger.info(f"Cleaned up {removed_count} old predictions")
            
        except Exception as e:
            self.logger.error(f"Failed to cleanup old predictions: {e}")
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∞–≤–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞ –ª–æ–≥–Ω–∞—Ç–∏—Ç–µ –ø—Ä–æ–≥–Ω–æ–∑–∏
        
        Returns:
            Dictionary —Å—ä—Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        """
        if not os.path.exists(self.history_file):
            return {'error': 'No prediction history found'}
        
        try:
            df = pd.read_parquet(self.history_file)
            
            total_predictions = len(df)
            with_results = df['actual_home_score'].notna().sum()
            pending_results = total_predictions - with_results
            
            # –î–∞—Ç–∞ range
            df['prediction_date'] = pd.to_datetime(df['prediction_date'])
            date_range = {
                'earliest': df['prediction_date'].min().isoformat(),
                'latest': df['prediction_date'].max().isoformat()
            }
            
            # Leagues
            league_counts = df['league'].value_counts().to_dict()
            
            # Recent activity (last 7 days)
            recent_cutoff = datetime.now() - timedelta(days=7)
            recent_predictions = df[df['prediction_date'] >= recent_cutoff]
            
            return {
                'total_predictions': int(total_predictions),
                'predictions_with_results': int(with_results),
                'pending_results': int(pending_results),
                'completion_rate': float(with_results / total_predictions) if total_predictions > 0 else 0,
                'date_range': date_range,
                'leagues': league_counts,
                'recent_activity': {
                    'last_7_days': len(recent_predictions),
                    'avg_per_day': len(recent_predictions) / 7
                },
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            return {'error': f'Failed to get statistics: {e}'}


# Middleware –∑–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –ª–æ–≥–≤–∞–Ω–µ –≤ API
def create_prediction_logging_middleware(logger: PredictionLogger):
    """
    –°—ä–∑–¥–∞–≤–∞ middleware –∑–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –ª–æ–≥–≤–∞–Ω–µ –Ω–∞ API –ø—Ä–æ–≥–Ω–æ–∑–∏
    """
    def log_prediction_middleware(request_data: Dict, response_data: Dict):
        """
        Middleware —Ñ—É–Ω–∫—Ü–∏—è –∑–∞ –ª–æ–≥–≤–∞–Ω–µ
        """
        try:
            # –ò–∑–≤–ª–∏—á–∞ –¥–∞–Ω–Ω–∏ –æ—Ç request
            home_team = request_data.get('home_team')
            away_team = request_data.get('away_team')
            league = request_data.get('league', 'Unknown')
            match_date = request_data.get('date')
            
            if home_team and away_team and 'prediction_1x2' in response_data:
                logger.log_prediction(
                    home_team=home_team,
                    away_team=away_team,
                    league=league,
                    prediction_data=response_data,
                    match_date=match_date
                )
        except Exception as e:
            logging.error(f"Failed to log prediction: {e}")
    
    return log_prediction_middleware


if __name__ == "__main__":
    # –¢–µ—Å—Ç–≤–∞–Ω–µ –Ω–∞ PredictionLogger
    print("üß™ –¢–µ—Å—Ç–≤–∞–Ω–µ –Ω–∞ PredictionLogger...")
    
    logger = PredictionLogger(
        history_file="test_predictions.parquet",
        results_file="test_results.parquet"
    )
    
    # –°–∏–º—É–ª–∏—Ä–∞–Ω–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞
    test_prediction = {
        'prediction_1x2': {
            'prob_home_win': 0.45,
            'prob_draw': 0.30,
            'prob_away_win': 0.25,
            'predicted_outcome': '1',
            'confidence': 0.45
        },
        'prediction_ou25': {
            'prob_over': 0.65,
            'prob_under': 0.35,
            'predicted_outcome': 'Over',
            'confidence': 0.65
        },
        'prediction_btts': {
            'prob_yes': 0.55,
            'prob_no': 0.45,
            'predicted_outcome': 'Yes',
            'confidence': 0.55
        },
        'fii': {
            'score': 7.2,
            'confidence_level': 'High'
        }
    }
    
    # –õ–æ–≥–≤–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞
    prediction_id = logger.log_prediction(
        home_team="Test Home",
        away_team="Test Away",
        league="Test League",
        prediction_data=test_prediction
    )
    
    print(f"‚úÖ Logged prediction: {prediction_id}")
    
    # –û–±–Ω–æ–≤—è–≤–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç
    success = logger.update_match_result(
        home_team="Test Home",
        away_team="Test Away",
        home_score=2,
        away_score=1,
        match_date=datetime.now().strftime('%Y-%m-%d')
    )
    
    print(f"‚úÖ Updated result: {success}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    stats = logger.get_statistics()
    print(f"‚úÖ Statistics: {stats}")
    
    # Cleanup
    os.remove("test_predictions.parquet")
    print("‚úÖ PredictionLogger —Ä–∞–±–æ—Ç–∏!")
