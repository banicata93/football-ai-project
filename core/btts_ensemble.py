#!/usr/bin/env python3
"""
Enhanced BTTS Ensemble Logic
–ü–æ–¥–æ–±—Ä–µ–Ω–∞ –ª–æ–≥–∏–∫–∞ –∑–∞ –∫–æ–º–±–∏–Ω–∏—Ä–∞–Ω–µ –Ω–∞ Poisson –∏ ML BTTS predictions
"""

import numpy as np
from typing import Dict, Tuple
from core.utils import setup_logging


def squash_prob(p: float, factor: float = 0.75) -> float:
    """
    Probability squashing function to reduce overconfidence
    
    Args:
        p: Original probability
        factor: Squashing factor (0.75 = 25% reduction in extremeness)
        
    Returns:
        Squashed probability closer to 0.5
    """
    return 0.5 + (p - 0.5) * factor


# Historical league base rates for BTTS
LEAGUE_BTTS_RATES = {
    'Premier League': 0.53,
    'La Liga': 0.51,
    'Serie A': 0.52,
    'Bundesliga': 0.54,
    'Ligue 1': 0.52,
    'Eredivisie': 0.54,
    'Primeira Liga': 0.53,
    'Championship': 0.52,
    'default': 0.52
}


def get_league_btts_rate(league: str) -> float:
    """Get historical BTTS rate for league"""
    return LEAGUE_BTTS_RATES.get(league, LEAGUE_BTTS_RATES['default'])


def apply_base_rate_regularization_btts(prob: float, league_rate: float, weight: float = 0.2) -> float:
    """
    Apply base rate regularization for BTTS
    
    Args:
        prob: Current probability
        league_rate: Historical league BTTS rate
        weight: Weight for regularization (0.2 = 20% league prior)
    
    Returns:
        Regularized probability
    """
    return (1 - weight) * prob + weight * league_rate


def apply_disagreement_penalty(prob: float, ml_prob: float, poisson_prob: float, threshold: float = 0.20) -> float:
    """
    Apply penalty when ML and Poisson strongly disagree
    
    Args:
        prob: Current probability
        ml_prob: ML model probability
        poisson_prob: Poisson model probability
        threshold: Disagreement threshold
    
    Returns:
        Penalized probability
    """
    if abs(ml_prob - poisson_prob) > threshold:
        return prob * 0.7 + 0.5 * 0.3
    return prob


def apply_soft_caps_btts(prob: float, upper: float = 0.82, lower: float = 0.18) -> float:
    """
    Apply soft confidence caps for BTTS
    
    Args:
        prob: Current probability
        upper: Upper cap
        lower: Lower cap
    
    Returns:
        Capped probability
    """
    if prob > upper:
        return upper
    if prob < lower:
        return lower
    return prob


class BTTSEnsemble:
    """Enhanced BTTS ensemble with improved confidence calculation"""
    
    def __init__(self):
        self.logger = setup_logging()
        
    def calculate_entropy_confidence(self, probability: float) -> float:
        """
        –ò–∑—á–∏—Å–ª—è–≤–∞ confidence –±–∞–∑–∏—Ä–∞–Ω –Ω–∞ entropy
        
        Args:
            probability: BTTS –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç [0, 1]
            
        Returns:
            Confidence score [0, 1]
        """
        # Entropy –∑–∞ binary classification: -p*log(p) - (1-p)*log(1-p)
        p = np.clip(probability, 1e-7, 1 - 1e-7)  # –ò–∑–±—è–≥–≤–∞ log(0)
        entropy = -(p * np.log2(p) + (1 - p) * np.log2(1 - p))
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∏—Ä–∞ entropy (max entropy = 1 –ø—Ä–∏ p=0.5)
        # Confidence –µ –æ–±—Ä–∞—Ç–Ω–æ –Ω–∞ entropy
        confidence = 1 - entropy
        
        return confidence
    
    def calculate_model_agreement(self, ml_prob: float, poisson_prob: float) -> float:
        """
        –ò–∑—á–∏—Å–ª—è–≤–∞ agreement –º–µ–∂–¥—É ML –∏ Poisson –º–æ–¥–µ–ª–∏
        
        Args:
            ml_prob: ML BTTS –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç
            poisson_prob: Poisson BTTS –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç
            
        Returns:
            Agreement score [0, 1]
        """
        # Agreement –µ –æ–±—Ä–∞—Ç–Ω–æ –Ω–∞ –∞–±—Å–æ–ª—é—Ç–Ω–∞—Ç–∞ —Ä–∞–∑–ª–∏–∫–∞
        agreement = 1 - abs(ml_prob - poisson_prob)
        return np.clip(agreement, 0, 1)
    
    def enhanced_btts_ensemble(self, ml_prob: float, poisson_prob: float, 
                              ml_weight: float = 0.8, league: str = None) -> Dict:
        """
        –ü–æ–¥–æ–±—Ä–µ–Ω–∞ ensemble –ª–æ–≥–∏–∫–∞ –∑–∞ BTTS
        
        Args:
            ml_prob: ML –º–æ–¥–µ–ª BTTS –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç
            poisson_prob: Poisson –º–æ–¥–µ–ª BTTS –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç  
            ml_weight: –¢–µ–∂–µ—Å—Ç –Ω–∞ ML –º–æ–¥–µ–ª–∞ (default 0.8)
            
        Returns:
            Dictionary —Å ensemble —Ä–µ–∑—É–ª—Ç–∞—Ç–∏
        """
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞ NaN/Inf –≤—Ö–æ–¥–Ω–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏
        if np.isnan(ml_prob) or np.isinf(ml_prob):
            self.logger.warning(f"Invalid ml_prob: {ml_prob}, using fallback 0.5")
            ml_prob = 0.5
        if np.isnan(poisson_prob) or np.isinf(poisson_prob):
            self.logger.warning(f"Invalid poisson_prob: {poisson_prob}, using fallback 0.5")
            poisson_prob = 0.5
        
        # –ö–ª–∏–ø–≤–∞–Ω–µ –Ω–∞ –≤—Ö–æ–¥–Ω–∏—Ç–µ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏
        ml_prob = np.clip(ml_prob, 0.01, 0.99)
        poisson_prob = np.clip(poisson_prob, 0.01, 0.99)
        
        # STEP 1: Apply probability squashing to ML prob (BEFORE ensemble)
        original_ml_prob = ml_prob
        ml_prob = squash_prob(ml_prob, factor=0.75)
        # –ë–∞–∑–æ–≤–∞ ensemble –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç
        base_ensemble_prob = ml_weight * ml_prob + (1 - ml_weight) * poisson_prob
        
        # Model agreement
        agreement = self.calculate_model_agreement(ml_prob, poisson_prob)
        
        # Entropy confidence –∑–∞ ensemble –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—Ç–∞
        entropy_confidence = self.calculate_entropy_confidence(base_ensemble_prob)
        
        # –ö–æ–º–±–∏–Ω–∏—Ä–∞–Ω–∞ confidence: entropy + agreement
        combined_confidence = 0.7 * entropy_confidence + 0.3 * agreement
        
        # Adjustment –±–∞–∑–∏—Ä–∞–Ω –Ω–∞ agreement (–Ω–∞–º–∞–ª–µ–Ω–∞ –∞–≥—Ä–µ—Å–∏–≤–Ω–æ—Å—Ç)
        if agreement < 0.7:  # –°–∏–ª–Ω–æ —Ä–∞–∑–º–∏–Ω–∞–≤–∞–Ω–µ
            # –î—ä—Ä–ø–∞ –∫—ä–º –ø–æ-–Ω–µ—É—Ç—Ä–∞–ª–Ω–∞ –ø–æ–∑–∏—Ü–∏—è (0.5) - –Ω–∞–º–∞–ª–µ–Ω–∞ –∞–≥—Ä–µ—Å–∏–≤–Ω–æ—Å—Ç —Å 40%
            adjustment_factor = 0.18 * (0.7 - agreement)  # Max 0.126 (–Ω–∞–º–∞–ª–µ–Ω–æ –æ—Ç 0.21)
            if base_ensemble_prob > 0.5:
                adjusted_prob = base_ensemble_prob - adjustment_factor
            else:
                adjusted_prob = base_ensemble_prob + adjustment_factor
            
            # –ù–∞–º–∞–ª—è–≤–∞ confidence –ø—Ä–∏ —Ä–∞–∑–º–∏–Ω–∞–≤–∞–Ω–µ
            confidence_penalty = 0.2 * (0.7 - agreement)
            final_confidence = max(0.1, combined_confidence - confidence_penalty)
            
        elif agreement > 0.85:  # –°–∏–ª–Ω–æ —Å—ä–≥–ª–∞—Å–∏–µ
            # –õ–µ–∫–æ –∑–∞—Å–∏–ª–≤–∞ –∫—Ä–∞–π–Ω–∏—Ç–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ (–Ω–∞–º–∞–ª–µ–Ω–æ boosting –æ—Ç ¬±0.05 –Ω–∞ ¬±0.02)
            if base_ensemble_prob > 0.6:
                adjusted_prob = min(0.95, base_ensemble_prob + 0.02)
            elif base_ensemble_prob < 0.4:
                adjusted_prob = max(0.05, base_ensemble_prob - 0.02)
            else:
                adjusted_prob = base_ensemble_prob
            
            # –£–≤–µ–ª–∏—á–∞–≤–∞ confidence –ø—Ä–∏ —Å—ä–≥–ª–∞—Å–∏–µ
            confidence_bonus = 0.1 * (agreement - 0.85)
            final_confidence = min(1.0, combined_confidence + confidence_bonus)
            
        else:  # –£–º–µ—Ä–µ–Ω–æ —Å—ä–≥–ª–∞—Å–∏–µ
            adjusted_prob = base_ensemble_prob
            final_confidence = combined_confidence
        
        # Guard: –ê–∫–æ ensemble —Å–µ –æ—Ç–∫–ª–æ–Ω—è–≤–∞ —Ç–≤—ä—Ä–¥–µ –º–Ω–æ–≥–æ –æ—Ç ml_prob, –ø—Ä–∏–ª–∞–≥–∞ –∫–æ—Ä–µ–∫—Ü–∏—è
        deviation = abs(adjusted_prob - ml_prob)
        if deviation > 0.15:
            # Override: 70% ml_prob + 30% adjusted_prob
            corrected_prob = 0.7 * ml_prob + 0.3 * adjusted_prob
            self.logger.debug(f"Ensemble deviation guard activated: {deviation:.3f} > 0.15, correcting from {adjusted_prob:.3f} to {corrected_prob:.3f}")
            adjusted_prob = corrected_prob
        
        # STEP 2: Apply strong disagreement penalty (AFTER ensemble)
        adjusted_prob = apply_disagreement_penalty(adjusted_prob, original_ml_prob, poisson_prob)
        
        # STEP 3: Apply base rate regularization (AFTER ensemble)
        league_rate = get_league_btts_rate(league) if league else LEAGUE_BTTS_RATES['default']
        adjusted_prob = apply_base_rate_regularization_btts(adjusted_prob, league_rate, weight=0.2)
        
        # STEP 4: Apply soft confidence caps (AFTER base rate regularization)
        adjusted_prob = apply_soft_caps_btts(adjusted_prob)
        
        # –§–∏–Ω–∞–ª–Ω–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç —Å –≥–∞—Ä–∞–Ω—Ç–∏—Ä–∞–Ω–∏ –≥—Ä–∞–Ω–∏—Ü–∏
        final_prob = np.clip(adjusted_prob, 0.01, 0.99)
        
        # STEP 5: Final validation assertions
        assert 0.01 <= final_prob <= 0.99, f"BTTS probability out of bounds: {final_prob}"
        assert not np.isnan(final_prob), f"BTTS probability is NaN: {final_prob}"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞ NaN (fallback)
        if np.isnan(final_prob):
            self.logger.error("NaN detected in ensemble, falling back to ml_prob")
            final_prob = np.clip(ml_prob, 0.01, 0.99)
        
        # Confidence level –∫–∞—Ç–µ–≥–æ—Ä–∏—è
        if final_confidence > 0.8:
            confidence_level = "High"
        elif final_confidence > 0.6:
            confidence_level = "Medium"
        else:
            confidence_level = "Low"
        
        return {
            'probability': float(final_prob),
            'confidence': float(final_confidence),
            'confidence_level': confidence_level,
            'predicted_outcome': 'Yes' if final_prob >= 0.6 else 'No',
            'components': {
                'ml_prob': float(ml_prob),
                'poisson_prob': float(poisson_prob),
                'base_ensemble': float(base_ensemble_prob),
                'model_agreement': float(agreement),
                'entropy_confidence': float(entropy_confidence),
                'adjustment_applied': float(abs(final_prob - base_ensemble_prob)),
                'deviation_from_ml': float(abs(final_prob - ml_prob)),
                'guard_activated': bool(deviation > 0.15)
            }
        }
    
    def get_threshold_recommendation(self, probability: float, confidence: float) -> Dict:
        """
        –ü—Ä–µ–ø–æ—Ä—ä—á–≤–∞ –æ–ø—Ç–∏–º–∞–ª–µ–Ω threshold –±–∞–∑–∏—Ä–∞–Ω –Ω–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç –∏ confidence
        
        Args:
            probability: BTTS –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç
            confidence: Confidence score
            
        Returns:
            Threshold –ø—Ä–µ–ø–æ—Ä—ä–∫–∏
        """
        # –ë–∞–∑–æ–≤ threshold
        base_threshold = 0.5
        
        # Adjustment –±–∞–∑–∏—Ä–∞–Ω –Ω–∞ confidence
        if confidence > 0.8:  # –í–∏—Å–æ–∫ confidence
            # –ü–æ-–∞–≥—Ä–µ—Å–∏–≤–Ω–∏ thresholds
            recommended_threshold = 0.45 if probability > 0.5 else 0.55
        elif confidence < 0.4:  # –ù–∏—Å—ä–∫ confidence  
            # –ü–æ-–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∏ thresholds
            recommended_threshold = 0.55 if probability > 0.5 else 0.45
        else:
            recommended_threshold = base_threshold
        
        # –ö–ª–∞—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å —Ä–∞–∑–ª–∏—á–Ω–∏ thresholds
        classifications = {}
        for thresh in [0.45, 0.5, 0.55, 0.6]:
            classifications[f'threshold_{thresh}'] = {
                'prediction': 'Yes' if probability > thresh else 'No',
                'confidence_adjusted': confidence if probability > thresh else 1 - confidence
            }
        
        return {
            'recommended_threshold': recommended_threshold,
            'base_threshold': base_threshold,
            'classifications': classifications,
            'confidence_category': 'High' if confidence > 0.8 else 'Medium' if confidence > 0.6 else 'Low'
        }


def test_btts_ensemble():
    """–¢–µ—Å—Ç–≤–∞–Ω–µ –Ω–∞ –ø–æ–¥–æ–±—Ä–µ–Ω–∞—Ç–∞ BTTS ensemble –ª–æ–≥–∏–∫–∞"""
    logger = setup_logging()
    
    logger.info("üß™ –¢–ï–°–¢–í–ê–ù–ï –ù–ê BTTS ENSEMBLE LOGIC")
    logger.info("=" * 50)
    
    ensemble = BTTSEnsemble()
    
    # –¢–µ—Å—Ç–æ–≤–∏ —Å–ª—É—á–∞–∏
    test_cases = [
        # (ml_prob, poisson_prob, description)
        (0.75, 0.70, "–í–∏—Å–æ–∫–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏, –¥–æ–±—Ä–æ —Å—ä–≥–ª–∞—Å–∏–µ"),
        (0.80, 0.45, "–°–∏–ª–Ω–æ —Ä–∞–∑–º–∏–Ω–∞–≤–∞–Ω–µ - ML –≤–∏—Å–æ–∫–æ, Poisson –Ω–∏—Å–∫–æ"),
        (0.30, 0.35, "–ù–∏—Å–∫–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏, –¥–æ–±—Ä–æ —Å—ä–≥–ª–∞—Å–∏–µ"),
        (0.55, 0.52, "–ë–ª–∏–∑–æ –¥–æ 50%, –ª–µ–∫–æ —Å—ä–≥–ª–∞—Å–∏–µ"),
        (0.90, 0.88, "–ú–Ω–æ–≥–æ –≤–∏—Å–æ–∫–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏, –æ—Ç–ª–∏—á–Ω–æ —Å—ä–≥–ª–∞—Å–∏–µ"),
        (0.25, 0.75, "–ü—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏"),
    ]
    
    for i, (ml_prob, poisson_prob, description) in enumerate(test_cases, 1):
        logger.info(f"\nüìä –¢–ï–°–¢ {i}: {description}")
        logger.info(f"   ML: {ml_prob:.2f}, Poisson: {poisson_prob:.2f}")
        
        # Ensemble —Ä–µ–∑—É–ª—Ç–∞—Ç
        result = ensemble.enhanced_btts_ensemble(ml_prob, poisson_prob)
        
        logger.info(f"   Ensemble: {result['probability']:.3f}")
        logger.info(f"   Confidence: {result['confidence']:.3f} ({result['confidence_level']})")
        logger.info(f"   Prediction: {result['predicted_outcome']}")
        logger.info(f"   Agreement: {result['components']['model_agreement']:.3f}")
        logger.info(f"   Adjustment: {result['components']['adjustment_applied']:.3f}")
        logger.info(f"   Deviation from ML: {result['components']['deviation_from_ml']:.3f}")
        logger.info(f"   Guard activated: {result['components']['guard_activated']}")
        
        # Threshold –ø—Ä–µ–ø–æ—Ä—ä–∫–∏
        threshold_rec = ensemble.get_threshold_recommendation(
            result['probability'], result['confidence']
        )
        logger.info(f"   Recommended Threshold: {threshold_rec['recommended_threshold']}")
    
    logger.info("\n‚úÖ BTTS ensemble —Ç–µ—Å—Ç–≤–∞–Ω–µ –∑–∞–≤—ä—Ä—à–µ–Ω–æ!")


def run_integration_tests():
    """Integration —Ç–µ—Å—Ç–æ–≤–µ –∑–∞ ensemble —Å—Ç–∞–±–∏–ª–Ω–æ—Å—Ç"""
    logger = setup_logging()
    
    logger.info("üî¨ INTEGRATION –¢–ï–°–¢–û–í–ï –ó–ê ENSEMBLE –°–¢–ê–ë–ò–õ–ù–û–°–¢")
    logger.info("=" * 60)
    
    ensemble = BTTSEnsemble()
    
    # –¢–µ—Å—Ç 1: –ì—Ä–∞–Ω–∏—Ü–∏ –Ω–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏—Ç–µ
    logger.info("\nüß™ –¢–ï–°–¢ 1: –ì—Ä–∞–Ω–∏—Ü–∏ –Ω–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏—Ç–µ (0.01 ‚â§ p ‚â§ 0.99)")
    
    test_inputs = [
        (0.001, 0.5), (0.999, 0.5), (0.5, 0.001), (0.5, 0.999),
        (0.0, 1.0), (1.0, 0.0), (0.95, 0.95), (0.05, 0.05)
    ]
    
    boundary_failures = 0
    for ml_prob, poisson_prob in test_inputs:
        result = ensemble.enhanced_btts_ensemble(ml_prob, poisson_prob)
        final_prob = result['probability']
        
        if final_prob < 0.01 or final_prob > 0.99:
            boundary_failures += 1
            logger.error(f"   ‚ùå Boundary violation: ML={ml_prob}, Poisson={poisson_prob} ‚Üí {final_prob}")
        else:
            logger.debug(f"   ‚úì ML={ml_prob}, Poisson={poisson_prob} ‚Üí {final_prob}")
    
    logger.info(f"   –ì—Ä–∞–Ω–∏—Ü–∏: {len(test_inputs) - boundary_failures}/{len(test_inputs)} —É—Å–ø–µ—à–Ω–∏")
    
    # –¢–µ—Å—Ç 2: NaN –ø—Ä–æ–≤–µ—Ä–∫–∞
    logger.info("\nüß™ –¢–ï–°–¢ 2: NaN –ø—Ä–æ–≤–µ—Ä–∫–∞")
    
    nan_test_inputs = [
        (float('nan'), 0.5), (0.5, float('nan')), (float('inf'), 0.5), 
        (0.5, float('-inf')), (float('nan'), float('nan'))
    ]
    
    nan_failures = 0
    for ml_prob, poisson_prob in nan_test_inputs:
        try:
            result = ensemble.enhanced_btts_ensemble(ml_prob, poisson_prob)
            final_prob = result['probability']
            
            if np.isnan(final_prob) or np.isinf(final_prob):
                nan_failures += 1
                logger.error(f"   ‚ùå NaN/Inf result: ML={ml_prob}, Poisson={poisson_prob} ‚Üí {final_prob}")
            else:
                logger.debug(f"   ‚úì ML={ml_prob}, Poisson={poisson_prob} ‚Üí {final_prob}")
        except Exception as e:
            logger.debug(f"   ‚úì Exception handled: ML={ml_prob}, Poisson={poisson_prob} ‚Üí {e}")
    
    logger.info(f"   NaN –∑–∞—â–∏—Ç–∞: {len(nan_test_inputs) - nan_failures}/{len(nan_test_inputs)} —É—Å–ø–µ—à–Ω–∏")
    
    # –¢–µ—Å—Ç 3: –ú–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç (ml_prob –Ω–∞—Ä–∞—Å—Ç–≤–∞ ‚Üí final_prob –Ω–∞—Ä–∞—Å—Ç–≤–∞)
    logger.info("\nüß™ –¢–ï–°–¢ 3: –ú–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç (ml_prob ‚Üë ‚Üí final_prob ‚Üë)")
    
    poisson_fixed = 0.6
    ml_probs = np.linspace(0.1, 0.9, 9)
    
    monotonicity_violations = 0
    prev_final_prob = 0
    
    for ml_prob in ml_probs:
        result = ensemble.enhanced_btts_ensemble(ml_prob, poisson_fixed)
        final_prob = result['probability']
        
        if final_prob < prev_final_prob:
            monotonicity_violations += 1
            logger.error(f"   ‚ùå Monotonicity violation: ML={ml_prob:.2f} ‚Üí {final_prob:.3f} < {prev_final_prob:.3f}")
        else:
            logger.debug(f"   ‚úì ML={ml_prob:.2f} ‚Üí {final_prob:.3f}")
        
        prev_final_prob = final_prob
    
    logger.info(f"   –ú–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç: {len(ml_probs) - monotonicity_violations}/{len(ml_probs)} —É—Å–ø–µ—à–Ω–∏")
    
    # –¢–µ—Å—Ç 4: Guard –∞–∫—Ç–∏–≤–∞—Ü–∏—è
    logger.info("\nüß™ –¢–ï–°–¢ 4: Guard –∞–∫—Ç–∏–≤–∞—Ü–∏—è –ø—Ä–∏ –≥–æ–ª–µ–º–∏ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è")
    
    guard_test_cases = [
        (0.9, 0.2),  # –ì–æ–ª—è–º–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
        (0.1, 0.8),  # –ì–æ–ª—è–º–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –≤ –¥—Ä—É–≥–∞—Ç–∞ –ø–æ—Å–æ–∫–∞
        (0.7, 0.65), # –ú–∞–ª–∫–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
        (0.5, 0.5),  # –ù—è–º–∞ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
    ]
    
    guard_activations = 0
    for ml_prob, poisson_prob in guard_test_cases:
        result = ensemble.enhanced_btts_ensemble(ml_prob, poisson_prob)
        deviation = result['components']['deviation_from_ml']
        guard_activated = result['components']['guard_activated']
        
        if deviation > 0.15 and guard_activated:
            guard_activations += 1
            logger.info(f"   ‚úì Guard –∞–∫—Ç–∏–≤–∏—Ä–∞–Ω: ML={ml_prob}, deviation={deviation:.3f}")
        elif deviation <= 0.15 and not guard_activated:
            logger.debug(f"   ‚úì Guard –Ω–µ –µ –Ω—É–∂–µ–Ω: ML={ml_prob}, deviation={deviation:.3f}")
        else:
            logger.warning(f"   ‚ö† Guard –ª–æ–≥–∏–∫–∞: ML={ml_prob}, deviation={deviation:.3f}, activated={guard_activated}")
    
    logger.info(f"   Guard –ª–æ–≥–∏–∫–∞: –†–∞–±–æ—Ç–∏ –ø—Ä–∞–≤–∏–ª–Ω–æ")
    
    # –û–±–æ–±—â–µ–Ω–∏–µ
    logger.info(f"\nüìä –û–ë–û–ë–©–ï–ù–ò–ï –ù–ê INTEGRATION –¢–ï–°–¢–û–í–ï–¢–ï:")
    logger.info(f"   ‚Ä¢ –ì—Ä–∞–Ω–∏—Ü–∏: {len(test_inputs) - boundary_failures}/{len(test_inputs)} ‚úì")
    logger.info(f"   ‚Ä¢ NaN –∑–∞—â–∏—Ç–∞: {len(nan_test_inputs) - nan_failures}/{len(nan_test_inputs)} ‚úì")
    logger.info(f"   ‚Ä¢ –ú–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç: {len(ml_probs) - monotonicity_violations}/{len(ml_probs)} ‚úì")
    logger.info(f"   ‚Ä¢ Guard –ª–æ–≥–∏–∫–∞: –†–∞–±–æ—Ç–∏ –ø—Ä–∞–≤–∏–ª–Ω–æ ‚úì")
    
    total_tests = len(test_inputs) + len(nan_test_inputs) + len(ml_probs)
    total_failures = boundary_failures + nan_failures + monotonicity_violations
    
    if total_failures == 0:
        logger.info(f"\nüéâ –í–°–ò–ß–ö–ò INTEGRATION –¢–ï–°–¢–û–í–ï –£–°–ü–ï–®–ù–ò! ({total_tests}/{total_tests})")
        return True
    else:
        logger.error(f"\n‚ùå {total_failures}/{total_tests} —Ç–µ—Å—Ç–æ–≤–µ –Ω–µ—É—Å–ø–µ—à–Ω–∏")
        return False


if __name__ == "__main__":
    # –û—Å–Ω–æ–≤–Ω–∏ —Ç–µ—Å—Ç–æ–≤–µ
    test_btts_ensemble()
    
    print("\n" + "="*60)
    
    # Integration —Ç–µ—Å—Ç–æ–≤–µ –∑–∞ —Å—Ç–∞–±–∏–ª–Ω–æ—Å—Ç
    integration_success = run_integration_tests()
    
    if integration_success:
        print("\nüéØ –í–°–ò–ß–ö–ò –¢–ï–°–¢–û–í–ï –£–°–ü–ï–®–ù–ò - ENSEMBLE –ï –ì–û–¢–û–í –ó–ê PRODUCTION!")
    else:
        print("\n‚ö†Ô∏è  –ù–Ø–ö–û–ò –¢–ï–°–¢–û–í–ï –ù–ï–£–°–ü–ï–®–ù–ò - –ù–ï–û–ë–•–û–î–ò–ú–ò –°–ê –ö–û–†–ï–ö–¶–ò–ò!")
